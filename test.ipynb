{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디렉토리 'reference'가 생성되었습니다.\n",
      "디렉토리 'result'가 생성되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107714/2208113697.py:61: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Title: How Do Large Language Models Acquire Factual Knowledge During Pretraining?\n",
      "📝 Authors: Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, Minjoon Seo\n",
      "📅 Submitted: 2024-06-17 17:54:40+00:00\n",
      "🔗 PDF Link: http://arxiv.org/pdf/2406.11813v3\n",
      "📝 Abstract:\n",
      "Despite the recent observation that large language models (LLMs) can store\n",
      "substantial factual knowledge, there is a limited understanding of the\n",
      "mechanisms of how they acquire factual knowledge through pretraining. This work\n",
      "addresses this gap by studying how LLMs acquire factual knowledge during\n",
      "pretraining. The findings reveal several important insights into the dynamics\n",
      "of factual knowledge acquisition during pretraining. First, counterintuitively,\n",
      "we observe that pretraining on more data shows no significant improvement in\n",
      "the model's capability to acquire and maintain factual knowledge. Next, there\n",
      "is a power-law relationship between training steps and forgetting of\n",
      "memorization and generalization of factual knowledge, and LLMs trained with\n",
      "duplicated training data exhibit faster forgetting. Third, training LLMs with\n",
      "larger batch sizes can enhance the models' robustness to forgetting. Overall,\n",
      "our observations suggest that factual knowledge acquisition in LLM pretraining\n",
      "occurs by progressively increasing the probability of factual knowledge\n",
      "presented in the pretraining data at each step. However, this increase is\n",
      "diluted by subsequent forgetting. Based on this interpretation, we demonstrate\n",
      "that we can provide plausible explanations for recently observed behaviors of\n",
      "LLMs, such as the poor performance of LLMs on long-tail knowledge and the\n",
      "benefits of deduplicating the pretraining corpus.\n",
      "논문 저장 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107714/2208113697.py:90: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "논문 저장 완료!\n",
      "1 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "2 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "3 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "4 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "5 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "6 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "7 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "8 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "9 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "10 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "11 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "12 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "13 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "14 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "15 번째 논문 다운로드 완료\n",
      "16 번째 논문 다운로드 실패\n",
      "    Measuring causal effects of data statistics on language model’s ’factual’ predictions\n",
      "논문 저장 완료!\n",
      "17 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "18 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "19 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "20 번째 논문 다운로드 완료\n",
      "21 번째 논문 다운로드 실패\n",
      "    Olmo: Accelerating the science of language models\n",
      "22 번째 논문 다운로드 실패\n",
      "    Investigating learning dynamics of bert fine-tuning\n",
      "23 번째 논문 다운로드 실패\n",
      "    Training compute-optimal large language models\n",
      "논문 저장 완료!\n",
      "24 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "25 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "26 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "27 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "28 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "29 번째 논문 다운로드 완료\n",
      "30 번째 논문 다운로드 실패\n",
      "    Starcoder: may the source be with you!\n",
      "논문 저장 완료!\n",
      "31 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "32 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "33 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "34 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "35 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "36 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "37 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "38 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "39 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "40 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "41 번째 논문 다운로드 완료\n",
      "42 번째 논문 다운로드 실패\n",
      "    Noise-robust de-duplication at scale\n",
      "논문 저장 완료!\n",
      "43 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "44 번째 논문 다운로드 완료\n",
      "45 번째 논문 다운로드 실패\n",
      "    Emergent structures and training dynamics in large language models\n",
      "논문 저장 완료!\n",
      "46 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "47 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "48 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "49 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "50 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "51 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "52 번째 논문 다운로드 완료\n",
      "논문 저장 완료!\n",
      "53 번째 논문 다운로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "인용 논문과의 관련 지점 정리...: 100%|██████████| 11/11 [08:20<00:00, 45.48s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import arxiv\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from prompt import * \n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n",
    "\n",
    "class CitationLinker():\n",
    "    def __init__ (self, config):\n",
    "        self.target_id = config['arxiv_id']\n",
    "        self.preprocess_threhsold = config['preprocess_threhsold']\n",
    "        self.reference_ratio = config['reference_ratio']\n",
    "        self.reference_condition = config['reference_condition']\n",
    "        self.model = config['model']\n",
    "\n",
    "        self.essay_dir = Path(config['essay_dir'])\n",
    "        self.result_dir = Path(config['result_dir'])\n",
    "        CitationLinker.create_directory_if_not_exists(self.essay_dir)\n",
    "        CitationLinker.create_directory_if_not_exists(self.result_dir)\n",
    "\n",
    "        self.title = None\n",
    "        self.authors = None\n",
    "        self.submitted = None\n",
    "        self.abstract = None\n",
    "        self.pdf_url = None\n",
    "\n",
    "        self.basic_keys = [\"Title\", \"Authors\", \"Submitted\" ,\"Abstract\"]\n",
    "        self.references = ['References']\n",
    "        \n",
    "        self.content_config = config['content_keys']\n",
    "        self.content_keys = [value_dict[\"name\"] for _, value_dict in self.content_config.items()]\n",
    "        \n",
    "        # self.summarize_keys = list(set(self.content_keys) - set(self.references))\n",
    "        # self.reference_count_keys = [key for key in self.content_keys if key not in set(self.basic_keys + self.references)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_directory_if_not_exists(directory_path):\n",
    "        if not os.path.exists(directory_path):\n",
    "            os.makedirs(directory_path)\n",
    "            print(f\"디렉토리 '{directory_path}'가 생성되었습니다.\")\n",
    "        else:\n",
    "            raise FileExistsError(f\"에러: '{directory_path}' 디렉토리가 이미 존재합니다.\")\n",
    "\n",
    "    def _search_arxiv_pdf(self, arxiv_id):\n",
    "        search = arxiv.Search(id_list=[arxiv_id])\n",
    "        for result in search.results():\n",
    "            break\n",
    "        print(f\"📌 Title: {result.title}\")\n",
    "        print(f\"📝 Authors: {', '.join([author.name for author in result.authors])}\")\n",
    "        print(f\"📅 Submitted: {result.published}\")\n",
    "        print(f\"🔗 PDF Link: {result.pdf_url}\")\n",
    "        print(f\"📝 Abstract:\\n{result.summary}\")\n",
    "        self.title = result.title\n",
    "        self.authors = ', '.join([author.name for author in result.authors])\n",
    "        self.submitted = str(result.published)\n",
    "        self.abstract = result.summary\n",
    "        self.pdf_url = result.pdf_url\n",
    "\n",
    "    def _download_arxiv_pdf(self, pdf_url, save_path):\n",
    "        response = requests.get(pdf_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(save_path, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    file.write(chunk)\n",
    "        print(\"논문 저장 완료!\")\n",
    "\n",
    "    def _fetch_arxiv_paper(self, title, max_results=30):\n",
    "        \n",
    "        search = arxiv.Search(\n",
    "            query=title,\n",
    "            max_results=max_results, \n",
    "            sort_by=arxiv.SortCriterion.Relevance\n",
    "        )\n",
    "\n",
    "        for result in search.results():\n",
    "            if title[10:-10].lower().replace(\" \", \"\") in result.title.lower().replace(\" \", \"\"):\n",
    "                return ( {\n",
    "                    \"title\": result.title,\n",
    "                    \"abstract\": result.summary,\n",
    "                    \"pdf_url\": result.pdf_url\n",
    "                })\n",
    "            \n",
    "        return None \n",
    "\n",
    "    def _preprocess(self, save_path):\n",
    "        # 데이터를 불러와 섹션 별로 나눕니다.\n",
    "        loader = UnstructuredPDFLoader(save_path)\n",
    "        documents = loader.load()\n",
    "        processed_output = {}\n",
    "        for key, value_dict in self.content_config.items():\n",
    "            if value_dict['name'] == \"Title\":\n",
    "                processed_output[value_dict['name']]=self.title\n",
    "            elif value_dict['name'] == \"Authors\":\n",
    "                processed_output[value_dict['name']]=self.authors\n",
    "            elif value_dict['name'] == \"Submitted\":\n",
    "                processed_output[value_dict['name']]=self.submitted\n",
    "            elif value_dict['name'] == \"Abstract\":    \n",
    "                processed_output[value_dict['name']]=self.abstract\n",
    "            else:\n",
    "                processed_output[value_dict['name']]=documents[0].page_content.split(value_dict['deliminators']['forward'])[-1].split(value_dict['deliminators']['backward'])[0]\n",
    "\n",
    "        # basic_key가 아닌 섹션 중 threshold 미만으로 잘리면 모두 없앱니다.\n",
    "        threshold = self.preprocess_threhsold\n",
    "        for key in self.content_keys:\n",
    "            if key not in self.basic_keys:\n",
    "                result = []\n",
    "                for text in processed_output[key].split(\"\\n\"):\n",
    "                    if len(text) >= threshold:\n",
    "                        result.append(text)\n",
    "                processed_output[key] = \"\\n\".join(result)\n",
    "        \n",
    "        # 2000자 단위로 모두 자릅니다.\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=2000, \n",
    "                chunk_overlap=0  \n",
    "            )\n",
    "        \n",
    "        for key in self.content_keys:\n",
    "            documents = text_splitter.create_documents([processed_output[key]])\n",
    "            for doc in documents:\n",
    "                doc.metadata = {\"Title\": self.title, \"Key\": key} \n",
    "            processed_output[key] = documents\n",
    "\n",
    "        return processed_output\n",
    "    \n",
    "    @staticmethod\n",
    "    def _message_to_openai(message, model):\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            store=True,\n",
    "            messages=[{\"role\": \"user\", \"content\": message}],\n",
    "            temperature=0\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def forward(self):\n",
    "\n",
    "        # 논문 id를 받아서 논문을 다운 받습니다.\n",
    "        self._search_arxiv_pdf(arxiv_id=self.target_id)\n",
    "        title = self.title\n",
    "        save_path = self.essay_dir / f\"0-{title[:15]}.pdf\"\n",
    "        self._download_arxiv_pdf(\n",
    "            pdf_url=self.pdf_url, \n",
    "            save_path=save_path\n",
    "        )\n",
    "\n",
    "        # 텍스트 전처리\n",
    "        processed_output = self._preprocess(\n",
    "            save_path=save_path\n",
    "        )\n",
    "\n",
    "        # 기본 요약\n",
    "        essay = \"\"\n",
    "        for key in self.content_keys:\n",
    "            if key not in self.references:\n",
    "                for doc in processed_output[key]:\n",
    "                    essay += doc.page_content + \"\\n\\n\"\n",
    "        basic_summarize_message = basic_summarize_template.format(essay=essay)\n",
    "        response = CitationLinker._message_to_openai(message=basic_summarize_message, model=self.model)\n",
    "        with open(self.result_dir/\"basic_summary.json\", 'w', encoding=\"utf-8\") as f:\n",
    "            json.dump(response.choices[0].message.content, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # 참고문헌 목록화\n",
    "        reference_extraction_message = reference_extraction_template.format(references=processed_output['References'])\n",
    "        flag = True\n",
    "        while flag:\n",
    "            response = CitationLinker._message_to_openai(message=reference_extraction_message, model=self.model)\n",
    "            text = response.choices[0].message.content\n",
    "            text = re.sub(\"```json\",\"\",text)\n",
    "            text = re.sub(\"```\",\"\",text)\n",
    "            json_data = json.loads(text)\n",
    "            flag = False\n",
    "            \n",
    "        reference_dict = {}\n",
    "        for key, dict_data in json_data.items():\n",
    "            dict_data['Counter'] = 0\n",
    "            dict_data['Context'] = []\n",
    "            reference_dict[key] = dict_data\n",
    "        processed_output['References'] = deepcopy(reference_dict)\n",
    "\n",
    "        # 인용횟수 counting\n",
    "        for index in range(len(reference_count_template_dict)):\n",
    "            result = []\n",
    "            for key in self.content_keys:\n",
    "                if key not in self.basic_keys + self.references:\n",
    "                    for essay in processed_output[key]:\n",
    "                        reference_count_message = reference_count_template_dict[str(index)].format(references=reference_dict, essay=essay, condition=self.reference_condition)\n",
    "                        response = CitationLinker._message_to_openai(reference_count_message, model=self.model)\n",
    "                        try:\n",
    "                            text = response.choices[0].message.content\n",
    "                            text = re.sub(\"```json\",\"\",text)\n",
    "                            text = re.sub(\"```\",\"\",text)\n",
    "                            text_data = json.loads(text)\n",
    "                            result.append(text_data)\n",
    "                        except: \n",
    "                            text_data = None\n",
    "                        # items['References'] = text_data\n",
    "\n",
    "            for data in result:\n",
    "                for key, value_dict in data.items():\n",
    "                    processed_output[\"References\"][key]['Counter'] += value_dict['Counter']\n",
    "                    processed_output[\"References\"][key]['Context'].extend(value_dict['Context'])\n",
    "\n",
    "        # reference 논문 다운 받아오기\n",
    "        for index in range(len(processed_output['References'])):\n",
    "            title = processed_output['References'][str(index+1)]['Title']\n",
    "            try :\n",
    "                paper_info = self._fetch_arxiv_paper(title)\n",
    "                if paper_info is None:\n",
    "                    paper_info = self._fetch_arxiv_paper(title, 150)\n",
    "            except Exception as e:\n",
    "                print(index+1,\"번째 논문 예외 발생: \", e)\n",
    "                try :\n",
    "                    paper_info = self._fetch_arxiv_paper(title, None)\n",
    "                except:\n",
    "                    paper_info = None\n",
    "\n",
    "            if paper_info is not None:\n",
    "                pdf_url = paper_info['pdf_url']\n",
    "                abstract = paper_info['abstract']\n",
    "                processed_output['References'][str(index+1)]['abstract'] = abstract\n",
    "                processed_output['References'][str(index+1)]['pdf_url'] = pdf_url\n",
    "                save_path = self.essay_dir / (str(index+1)+ \"-\" + paper_info['title'][:15]+\".pdf\")\n",
    "                self._download_arxiv_pdf(pdf_url, save_path)\n",
    "                print(index+1,\"번째 논문 다운로드 완료\")\n",
    "            \n",
    "            else:\n",
    "                pdf_url = None\n",
    "                abstract = None\n",
    "                processed_output['References'][str(index+1)]['abstract'] = abstract\n",
    "                processed_output['References'][str(index+1)]['pdf_url'] = pdf_url\n",
    "                print(index+1,\"번째 논문 다운로드 실패\")\n",
    "                print(f\"    {processed_output['References'][str(index+1)]['Title']}\")\n",
    "\n",
    "        # 논문 다운로드 후, 질문 축소\n",
    "        filtered_reference_dict = { key: value for key, value in processed_output['References'].items() if value['pdf_url'] is not None}\n",
    "        nums = int(round(len(processed_output['References'])*self.reference_ratio, 0))\n",
    "        related_reference = dict(sorted(filtered_reference_dict.items(), key=lambda x:x[1]['Counter'], reverse=True)[:nums])\n",
    "        total_related_reference = dict(sorted(filtered_reference_dict.items(), key=lambda x:x[1]['Counter'], reverse=True))\n",
    "        # print(total_related_reference)\n",
    "        # result['total_reference_result_dict'] = total_related_reference\n",
    "        with open(self.result_dir/\"reference_count.json\", 'w', encoding=\"utf-8\") as f:\n",
    "            json.dump(total_related_reference, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        for index in related_reference.keys():\n",
    "            query_list = related_reference[index]['Context']\n",
    "            user_message = question_reduction_template.format(text_list=query_list)\n",
    "            response = CitationLinker._message_to_openai(user_message, model=self.model)\n",
    "            related_reference[index]['Questions'] = response.choices[0].message.content\n",
    "\n",
    "        # reference와의 접점을 찾기 위한 요약\n",
    "        main_essay = \"\"\n",
    "        for key in self.basic_keys:\n",
    "            for doc in processed_output[key]:\n",
    "                main_essay += (doc.page_content + \"\\n\\n\")\n",
    "\n",
    "        for index in tqdm(related_reference.keys(), desc=\"인용 논문과의 관련 지점 정리...\"):\n",
    "            title = related_reference[index]['Title']\n",
    "            questions = related_reference[index]['Questions']\n",
    "        \n",
    "            for path in self.essay_dir.rglob(\"*.pdf\"):\n",
    "                if path.name.split(\"-\")[0] == index:\n",
    "                    break\n",
    "        \n",
    "            loader = UnstructuredPDFLoader(path)\n",
    "            documents = loader.load()\n",
    "            essay = documents[0].page_content\n",
    "            essay = \"\\n\".join([text for text in essay.split(\"\\n\") if len(text) >= self.preprocess_threhsold])\n",
    "            reference_qna_message = reference_qna_template.format(essay = essay, questions=questions, title=title)\n",
    "            response = CitationLinker._message_to_openai(reference_qna_message, model=self.model)\n",
    "            summary = response.choices[0].message.content\n",
    "            related_reference[index]['Summary'] = summary\n",
    "            \n",
    "            research_progress_message = research_progress_template.format(title=processed_output['Title'], essay=main_essay, qna = summary)\n",
    "            response = CitationLinker._message_to_openai(research_progress_message,model=self.model)\n",
    "            summary_qna = response.choices[0].message.content\n",
    "            related_reference[index]['Summary_QnA'] = summary_qna\n",
    "\n",
    "        with open(self.result_dir/\"reference_qna.json\", 'w', encoding=\"utf-8\") as f:\n",
    "            json.dump(related_reference, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    with open(\"config.json\",'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    citation_linker = CitationLinker(config)\n",
    "    citation_linker.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. 기본 정보\n",
      "1) 제목: How Do Large Language Models Acquire Factual Knowledge During Pretraining?\n",
      "2) 저자: Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, Minjoon Seo\n",
      "\n",
      "### 2. 연구 목적\n",
      "1) 문제의식: 대형 언어 모델의 사실적 지식 습득 메커니즘\n",
      "2) 설명: 최근 대형 언어 모델(LLM)이 상당한 사실적 지식을 저장할 수 있다는 관찰이 있었으나, 이들이 사전 훈련 중 사실적 지식을 어떻게 습득하는지에 대한 이해는 부족하다. 본 연구는 LLM의 사실적 지식 습득 과정을 분석하여, 데이터 양 증가가 지식 습득에 미치는 영향, 훈련 조건에 따른 효과성, 그리고 습득한 지식의 망각 메커니즘을 탐구한다. 이를 통해 LLM의 훈련 동역학을 이해하고, 향후 연구 및 활용에 기여하고자 한다.\n",
      "\n",
      "### 3. 연구 방법\n",
      "1) 실험 방법: 연구진은 LLM의 중간 사전 훈련 체크포인트를 사용하여, 새로운 사실적 지식을 주입하고, 다양한 훈련 조건에서 지식 습득의 진행 상황을 모니터링하였다. \n",
      "2) 데이터: FICTIONAL KNOWLEDGE 데이터셋을 구성하여, 허구적이지만 현실적인 엔티티에 대한 설명을 포함한 문장을 주입하였다. 이 데이터셋은 GPT-4를 통해 생성되었다.\n",
      "3) 모델 및 분석 방법: OLMo 모델을 사용하여, 주입된 지식에 대한 로그 확률을 평가하고, 메모리화, 의미적 일반화, 구성적 일반화의 세 가지 깊이에서 지식 습득을 분석하였다. 또한, 효과성 및 유지 가능성을 측정하기 위한 지표를 정의하였다.\n",
      "\n",
      "### 4. 주요 결과\n",
      "1) 연구의 주요 발견: LLM은 사실적 지식을 습득할 때, 미세한 확률 증가를 누적하는 방식으로 작동하며, 훈련 단계가 진행됨에 따라 지식 습득의 효과성은 크게 개선되지 않는다는 것을 발견하였다. 또한, 훈련 단계와 망각 간의 파워-로우 관계가 존재하며, 중복된 데이터로 훈련된 모델은 더 빠르게 망각하는 경향이 있음을 확인하였다.\n",
      "2) 기여 및 성과: 본 연구는 LLM의 사실적 지식 습득 동역학을 세밀하게 분석하고, 데이터 중복 제거의 중요성과 대규모 배치 훈련의 이점을 강조함으로써, LLM의 훈련 및 성능 향상에 대한 새로운 통찰을 제공하였다.\n",
      "\n",
      "### 5. 결론 및 시사점\n",
      "1) 결론: LLM의 사실적 지식 습득은 주입된 지식의 반복적 노출을 통해 이루어지며, 망각은 훈련 단계가 진행됨에 따라 발생한다. \n",
      "2) 시사점: 연구 결과는 LLM의 훈련 데이터 구성 및 훈련 방법에 대한 중요한 시사점을 제공하며, LLM의 성능 향상을 위한 전략적 접근을 제안한다.\n",
      "3) 연구의 한계: 본 연구는 특정 모델과 데이터셋에 국한되어 있으며, 다양한 LLM 아키텍처와 데이터셋에 대한 일반화 가능성에 대한 추가 연구가 필요하다.\n",
      "4) 향후 연구 방향: LLM의 지식 습득 및 망각 메커니즘을 더 깊이 이해하기 위해, 다양한 유형의 지식과 훈련 조건을 탐구하는 후속 연구가 필요하다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"result/basic_summary.json\", 'r') as f:\n",
    "    basic_summary = json.load(f)\n",
    "\n",
    "print(basic_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인용 논문 제목 (Title): Scaling laws for neural language models\n",
      "\n",
      "1. **질문 :** [27]은 LLM의 성능이 모델 크기와 사전 훈련 코퍼스의 크기와 긍정적으로 상관관계가 있는 스케일링 법칙을 따름을 보고하였다.\n",
      "   - **답변 :** LLM의 성능은 모델 크기와 데이터셋 크기에 따라 증가하며, 이는 스케일링 법칙에 의해 설명된다. 즉, 모델의 크기와 훈련 데이터의 양이 증가할수록 성능이 향상된다는 것을 의미한다.\n",
      "   - **근거 :** \"Performance has a power-law relationship with each of the three scale factors N, D, C when not bottlenecked by the other two.\"\n",
      "\n",
      "2. **질문 :** 다음으로, 모델이 i번째로 지식을 제공받은 후 사실적 지식의 로그 확률에서 즉각적인 개선을 정량화하기 위한 메트릭을 정의한다.\n",
      "   - **답변 :** 모델이 특정 지식을 제공받은 후의 로그 확률 개선을 측정하기 위해 메트릭을 정의하는 것은 모델의 학습 효과를 평가하는 데 중요하다.\n",
      "   - **근거 :** \"We define a metric to quantify the immediate improvement in the model’s log probability of factual knowledge after it is presented with the knowledge for the i-th time.\"\n",
      "\n",
      "3. **질문 :** 정의된 메트릭의 측정은 그림 1에 설명되어 있다. 효과성과 유지 가능성의 측정을 위해 IQR 방법을 사용하여 이상치 탐지를 적용한다.\n",
      "   - **답변 :** 효과성과 유지 가능성을 측정하기 위해 IQR 방법을 사용하여 이상치를 탐지하는 것은 데이터의 신뢰성을 높이는 데 기여한다.\n",
      "   - **근거 :** \"For the measurement of effectivity and retainability, we apply outlier detection using the IQR method with a factor of 1.5.\"\n",
      "\n",
      "4. **질문 :** 결과는 중복(상단), 패러프레이즈(중앙), 한 번(하단) 주입 시나리오에 대해 보여진다.\n",
      "   - **답변 :** 다양한 주입 시나리오에서 모델의 성능 변화를 관찰하는 것은 지식 주입의 효과를 이해하는 데 도움이 된다.\n",
      "   - **근거 :** \"Results are shown for duplicate (Top), paraphrase (Center), and once (Bottom) injection scenarios.\"\n",
      "\n",
      "5. **질문 :** 획득 깊이에 관계없이(기억, 의미 일반화 및 조합 일반화), 주입된 지식을 포함한 배치로 모델이 업데이트된 후 프로브에서 측정된 모델의 로그 확률은 즉각적이고 뚜렷한 증가를 보인다.\n",
      "   - **답변 :** 모델이 주입된 지식으로 업데이트된 후 로그 확률이 즉각적으로 증가하는 것은 지식 주입의 효과를 나타낸다.\n",
      "   - **근거 :** \"The model’s log probability measured on the probes shows an immediate and distinctive increase, after the model is updated with the batch containing the injected knowledge.\"\n",
      "\n",
      "6. **질문 :** 우리가 조사하는 OLMo-7B의 모든 사전 훈련 단계에서 이러한 패턴은 일관되게 나타난다.\n",
      "   - **답변 :** OLMo-7B의 모든 사전 훈련 단계에서 일관된 패턴이 나타나는 것은 모델의 일반화 능력을 보여준다.\n",
      "   - **근거 :** \"These patterns are consistent across all pretraining stages of OLMo-7B we investigate.\"\n",
      "\n",
      "7. **질문 :** 그림 5의 추정된 x-절편은 훈련으로 획득한 사실적 지식의 완전한 손실로 이어지는 추가 훈련 토큰의 수를 나타낸다.\n",
      "   - **답변 :** x-절편의 추정치는 모델이 훈련을 통해 획득한 지식의 손실을 이해하는 데 중요한 정보를 제공한다.\n",
      "   - **근거 :** \"The estimated x-intercepts in Figure 5 represent the number of additional training tokens that would lead to the complete loss of the factual knowledge acquired by training.\"\n",
      "\n",
      "8. **질문 :** 훈련 단계와 획득한 사실적 지식의 망각 사이에는 멤모리제이션과 일반화 모두에 대해 거듭제곱 법칙 관계가 있다.\n",
      "   - **답변 :** 훈련 단계와 지식의 망각 사이의 관계는 모델의 학습 및 일반화 능력을 이해하는 데 중요한 통찰을 제공한다.\n",
      "   - **근거 :** \"There is a power-law relationship between training steps and forgetting of acquired factual knowledge, in terms of both memorization and generalization.\"\n",
      "\n",
      "9. **질문 :** LLM이 비인기 지식을 습득하는 데 어려움을 겪는 이유는 충분한 노출이 필요하기 때문이다.\n",
      "   - **답변 :** LLM이 비인기 지식을 습득하는 데 어려움을 겪는 것은 학습 가능성의 임계값보다 짧은 간격으로 사실적 지식에 충분히 노출되어야 하기 때문이다.\n",
      "   - **근거 :** \"We hypothesize that LLMs struggle to acquire unpopular knowledge because they need sufficient exposure to factual knowledge with intervals shorter than the learnability threshold to increase the probability.\"\n",
      "\n",
      "10. **질문 :** 모델은 모든 획득 깊이에서 로그 확률의 더 큰 개선을 보이지만, 망각도 더 빠르다.\n",
      "    - **답변 :** 모델이 모든 획득 깊이에서 로그 확률의 개선을 보이는 것은 지식 주입의 효과를 나타내지만, 망각이 더 빠르다는 점은 주의가 필요하다.\n",
      "    - **근거 :** \"The model shows a larger improvement of log probability in all acquisition depths, but also the forgetting is faster.\"\n",
      "\n",
      "11. **질문 :** 최근 관찰된, 그러나 충분히 탐구되지 않은 LLM의 행동에 대한 잠재적 설명을 제공한다.\n",
      "    - **답변 :** LLM의 행동에 대한 잠재적 설명을 제공하는 것은 모델의 이해를 심화하는 데 기여할 수 있다.\n",
      "    - **근거 :** \"We provide potential explanations for recently observed, yet underexplored behaviors of LLMs.\"\n",
      "\n",
      "12. **질문 :** Eq.1에서 지역 획득 최대값의 정의는 주입된 지식 k와 윈도우 크기 tw에 의존하지만, 간결함을 위해 tLAM(q, i)로 작성한다.\n",
      "    - **답변 :** 지역 획득 최대값의 정의는 주입된 지식과 윈도우 크기에 의존하며, 이는 모델의 성능을 평가하는 데 중요한 요소이다.\n",
      "    - **근거 :** \"The definition of the local acquisition maxima is also dependent on the injected knowledge k and the window size tw.\"\n",
      "\n",
      "13. **질문 :** 정의된 메트릭의 측정은 그림 1에 설명되어 있으며, 이는 LLM의 행동을 해석하는 데 중요하다.\n",
      "    - **답변 :** 정의된 메트릭의 측정은 LLM의 행동을 해석하는 데 중요한 역할을 하며, 이는 모델의 성능을 이해하는 데 기여한다.\n",
      "    - **근거 :** \"The measurement of the defined metrics are illustrated in Figure 1, which is crucial for interpreting the behaviors of LLMs.\"\n",
      "\n",
      "14. **질문 :** 데이터 스케일링을 통한 LLM의 성능 향상은 일관된 개선의 결과라고 제안한다.\n",
      "    - **답변 :** 데이터 스케일링을 통한 LLM의 성능 향상은 모델이 사실적 지식을 더 빠르게 습득하는 능력의 출현이 아니라 일관된 개선의 결과로 볼 수 있다.\n",
      "    - **근거 :** \"We propose that the improved performance of LLMs through data scaling results from consistent improvements rather than an emergent ability to acquire factual knowledge more quickly during pretraining.\"\n",
      "\n",
      "15. **질문 :** 이 경향은 모든 모델 스케일과 주입 시나리오에서 일관되게 나타난다.\n",
      "    - **답변 :** 모든 모델 스케일과 주입 시나리오에서 일관된 경향이 나타나는 것은 모델의 일반화 능력을 보여준다.\n",
      "    - **근거 :** \"This tendency is consistent across all model scales and injection scenarios.\"\n",
      "\n",
      "### 답변 요약 (Summary of Answers)\n",
      "이 논문에서는 LLM의 성능이 모델 크기와 데이터셋 크기에 따라 증가하는 스케일링 법칙을 제시하고 있다. 모델이 특정 지식을 제공받은 후의 로그 확률 개선을 정량화하기 위한 메트릭을 정의하며, 효과성과 유지 가능성을 측정하기 위해 IQR 방법을 사용한다. 다양한 주입 시나리오에서의 성능 변화를 관찰하고, 주입된 지식으로 업데이트된 후 로그 확률이 즉각적으로 증가하는 현상을 설명한다. 또한, LLM이 비인기 지식을 습득하는 데 어려움을 겪는 이유와 모델의 망각 속도에 대한 논의도 포함되어 있다. 이러한 결과들은 LLM의 성능 향상과 관련된 다양한 요인들을 이해하는 데 기여하며, 데이터 스케일링을 통한 성능 개선이 일관된 개선의 결과임을 강조한다.\n",
      "\n",
      "해당 논문은 LLM의 성능이 모델 크기와 데이터셋 크기에 따라 증가하는 스케일링 법칙을 기반으로, LLM이 사실적 지식을 어떻게 습득하는지를 심층적으로 분석하였다. 특히, 주입된 지식에 대한 로그 확률 개선을 정량화하는 메트릭을 정의하고, IQR 방법을 통해 효과성과 유지 가능성을 측정함으로써 데이터의 신뢰성을 높였다. 또한, LLM이 비인기 지식을 습득하는 데 어려움을 겪는 이유와 망각 속도에 대한 통찰을 제공하여, LLM의 성능 향상과 관련된 다양한 요인들을 이해하는 데 기여하였다. 이러한 연구는 LLM의 행동을 해석하고, 데이터 스케일링을 통한 성능 개선이 일관된 결과임을 강조하는 데 중요한 역할을 한다.\n",
      "##########\n",
      "\n",
      "### 인용 논문 제목 (Title): Deduplicating training data makes language models better\n",
      "\n",
      "1. **질문 :** LLMs는 상당량의 훈련 데이터를 기억하며, 모델의 크기가 커질수록 훈련 데이터를 기억하는 경향이 증가하지만, 지식을 일반화하는 능력에는 해를 끼치지 않는다.\n",
      "   - **답변 :** 대형 언어 모델(LLM)은 훈련 데이터의 상당 부분을 기억하는 경향이 있으며, 모델의 크기가 커질수록 이러한 경향이 더욱 두드러진다. 그러나 연구에 따르면 이러한 기억은 모델의 일반화 능력에 부정적인 영향을 미치지 않는다.\n",
      "   - **근거 :** \"LLMs memorize a significant amount of training data... without harming the ability to generalize the knowledge.\"\n",
      "\n",
      "2. **질문 :** LLM을 비중복 데이터와 더 큰 배치 크기로 사전 훈련하면 사실적 지식의 습득이 향상되어 학습한 사실적 지식을 잊어버리는 것에 대해 더 강해진다.\n",
      "   - **답변 :** 비중복 데이터와 큰 배치 크기로 LLM을 사전 훈련하면 모델이 사실적 지식을 더 잘 습득하게 되어, 학습한 지식을 잊어버리는 경향이 줄어든다.\n",
      "   - **근거 :** \"Pretraining LLMs with deduplicated data and larger batch sizes enhances the acquisition of factual knowledge...\"\n",
      "\n",
      "3. **질문 :** 사전 훈련 코퍼스를 비중복화하면 LLM 성능이 향상되며, 이는 모델이 중복된 시퀀스에 더 높은 확률을 부여하는 것을 방지하고, 습득한 일반화를 더 오래 유지하는 데 도움을 준다.\n",
      "   - **답변 :** 비중복화된 사전 훈련 코퍼스를 사용하면 LLM의 성능이 향상되며, 이는 모델이 중복된 데이터에 대한 확률을 낮추고, 학습한 일반화를 더 오래 유지할 수 있도록 돕는다.\n",
      "   - **근거 :** \"Our findings suggest that deduplicating the pretraining corpus improves LLM performance by preventing the model from assigning a higher probability to duplicated sequences...\"\n",
      "\n",
      "4. **질문 :** 사전 훈련 데이터의 비중복화는 모델 성능 향상에 중요한 요소로 널리 관찰된다.\n",
      "   - **답변 :** 사전 훈련 데이터의 비중복화는 모델 성능을 향상시키는 중요한 요소로 널리 인식되고 있으며, 이는 다양한 연구에서 확인되었다.\n",
      "   - **근거 :** \"It is widely observed that deduplication of pretraining data is an important factor in improving model performance...\"\n",
      "\n",
      "### 답변 요약 (Summary of Answers)\n",
      "대형 언어 모델(LLM)은 훈련 데이터의 상당 부분을 기억하는 경향이 있으며, 모델의 크기가 커질수록 이러한 경향이 더욱 두드러진다. 그러나 이러한 기억은 모델의 일반화 능력에 부정적인 영향을 미치지 않는다. 비중복 데이터와 큰 배치 크기로 LLM을 사전 훈련하면 사실적 지식의 습득이 향상되어 학습한 지식을 잊어버리는 경향이 줄어든다. 또한, 비중복화된 사전 훈련 코퍼스를 사용하면 LLM의 성능이 향상되며, 이는 모델이 중복된 데이터에 대한 확률을 낮추고, 학습한 일반화를 더 오래 유지할 수 있도록 돕는다. 이러한 비중복화는 모델 성능 향상에 중요한 요소로 널리 인식되고 있다.\n",
      "\n",
      "인용 논문 제목 (Title): <<Deduplicating training data makes language models better>>\n",
      "\n",
      "해당 논문은 대형 언어 모델(LLM)의 사실적 지식 습득 메커니즘을 탐구하며, 비중복 데이터와 큰 배치 크기가 모델의 성능 향상에 미치는 영향을 강조한다. 특히, 비중복화된 사전 훈련 코퍼스가 모델이 중복된 시퀀스에 대한 확률을 낮추고, 습득한 일반화를 더 오래 유지하도록 돕는다는 점을 통해, LLM의 기억과 일반화 간의 관계를 명확히 한다. 이러한 연구 결과는 LLM의 훈련 전략을 개선하는 데 기여하며, 사실적 지식의 습득과 유지에 대한 이해를 심화시킨다.\n",
      "##########\n",
      "\n",
      "인용 논문 제목 (Title): Memorization without overfitting: Analyzing the training dynamics of large language models\n",
      "\n",
      "1. **질문 :** [46]은 다양한 사전 훈련 조건에서 LLM의 암기 및 망각 행동에 대한 광범위한 분석을 수행했습니다.\n",
      "   - **답변 :** [46]의 연구는 대형 언어 모델(LLM)의 암기 및 망각 행동을 다양한 사전 훈련 조건에서 분석하였으며, 이 연구는 모델 크기, 데이터셋 크기, 학습률 등이 암기 동역학에 미치는 영향을 측정했습니다.\n",
      "   - **근거 :** \"We empirically study exact memorization in causal and masked language modeling, across model sizes and throughout the training process.\"\n",
      "\n",
      "2. **질문 :** [44]와 [46]은 언어 모델 사전 훈련에서 암기 동역학에 초점을 맞췄습니다.\n",
      "   - **답변 :** [44]와 [46]의 연구는 언어 모델의 사전 훈련 과정에서 암기 동역학을 분석하였으며, 특히 모델 크기가 커질수록 암기 속도가 빨라진다는 점을 강조했습니다.\n",
      "   - **근거 :** \"We find that larger language models memorize training data faster across all settings.\"\n",
      "\n",
      "3. **질문 :** 망각의 기하급수적 경향은 LLM 훈련의 다양한 측면에서 보고되었습니다.\n",
      "   - **답변 :** LLM 훈련에서 망각의 기하급수적 경향은 사전 훈련에서의 암기 및 지속적인 학습에서의 작업 성능 등 여러 측면에서 관찰되었습니다. 이는 모델 크기가 증가할수록 망각이 줄어드는 경향과 관련이 있습니다.\n",
      "   - **근거 :** \"We show that the forgetting baseline increases with model scale, i.e., increasing model scale mitigates forgetting.\"\n",
      "\n",
      "답변 요약 \n",
      ": 이 논문은 대형 언어 모델의 암기 및 망각 동역학을 분석하며, 특히 모델 크기가 커질수록 암기 속도가 빨라지고 망각이 줄어드는 경향을 보여줍니다. [46]의 연구는 다양한 사전 훈련 조건에서 LLM의 행동을 분석하였고, [44]와 [46]은 언어 모델의 사전 훈련에서 암기 동역학에 초점을 맞추었습니다. 또한, 망각의 기하급수적 경향은 LLM 훈련의 여러 측면에서 관찰되며, 이는 모델 크기가 증가할수록 망각이 줄어드는 경향과 관련이 있습니다. 이러한 발견은 대형 언어 모델의 훈련 동역학을 이해하는 데 중요한 기여를 합니다.\n",
      "\n",
      "인용 논문 제목 (Title): Memorization without overfitting: Analyzing the training dynamics of large language models\n",
      "\n",
      "해당 논문은 대형 언어 모델(LLM)의 암기 및 망각 동역학을 분석하여, 모델 크기가 커질수록 암기 속도가 빨라지고 망각이 줄어드는 경향을 보여줍니다. 이러한 연구는 LLM의 사전 훈련 과정에서의 암기 및 망각 행동을 이해하는 데 기여하며, [46]의 연구와 함께 다양한 사전 훈련 조건에서의 모델 행동을 심층적으로 분석합니다. 특히, 본 논문은 훈련 단계와 망각 간의 관계를 규명하고, 데이터 중복이 망각에 미치는 영향을 강조함으로써 LLM의 훈련 동역학에 대한 새로운 통찰을 제공합니다. 이러한 발견은 LLM의 사실적 지식 습득 메커니즘을 이해하는 데 중요한 기초 자료가 됩니다.\n",
      "##########\n",
      "\n",
      "인용 논문 제목 (Title): Are emergent abilities of large language models a mirage?\n",
      "\n",
      "1. **질문 :** LLM의 사실적 지식 습득을 상세히 분석하기 위해, 우리는 로그 확률을 검토하여 모델의 상태를 평가합니다. \n",
      "   - **답변 :** LLM의 사실적 지식 습득을 분석하기 위해 로그 확률을 통해 모델의 상태를 평가하는 방법은 모델이 훈련 중에 얼마나 많은 사실적 정보를 습득했는지를 세밀하게 파악할 수 있게 해줍니다. 이는 모델의 출력에서 나타나는 확률 분포를 분석하여, 특정 지식이 모델에 얼마나 잘 내재화되었는지를 평가하는 데 유용합니다.\n",
      "   - **근거 :** \"To conduct a detailed analysis of the LLMs’ acquisition of factual knowledge during pretraining, we evaluate the model’s state by examining log probabilities to obtain fine-grained information.\"\n",
      "\n",
      "2. **질문 :** 대부분의 잘 알려진 사실은 학습 가능성 임계값보다 짧은 훈련 단계 간격으로 모델에 제시될 가능성이 높습니다.\n",
      "   - **답변 :** LLM이 사실적 지식을 습득하는 과정에서, 잘 알려진 사실들은 모델이 학습할 수 있는 임계값보다 짧은 간격으로 제공되기 때문에, 이러한 사실들이 모델에 더 쉽게 내재화될 수 있습니다. 이는 모델이 훈련 초기 단계에서부터 이러한 정보를 빠르게 습득할 수 있음을 시사합니다.\n",
      "   - **근거 :** \"Most well-known facts are likely to be presented to the model with an interval of the training steps shorter than this learnability threshold.\"\n",
      "\n",
      "3. **질문 :** 이러한 지식의 습득은 모델의 상위 k 출력 시퀀스 생성에서 상대적으로 초기 훈련 단계에 반영될 것입니다.\n",
      "   - **답변 :** LLM이 특정 지식을 습득하는 과정은 초기 훈련 단계에서부터 모델의 출력 시퀀스에 반영되며, 이는 모델이 훈련 초기부터 특정 작업에 대한 성능을 발휘할 수 있음을 보여줍니다. 이러한 현상은 모델의 출력에서 나타나는 확률 분포와 관련이 있습니다.\n",
      "   - **근거 :** \"...the acquisition of such knowledge will be reflected in the model’s top-k output sequence generation in a relatively earlier pretraining stage.\"\n",
      "\n",
      "4. **질문 :** 지식의 누적 로그 확률은 모델의 디코딩 출력으로 지식을 생성하기에 충분히 높을 것입니다.\n",
      "   - **답변 :** LLM의 지식 습득 과정에서, 누적된 로그 확률이 충분히 높아지면 모델은 해당 지식을 디코딩 출력으로 생성할 수 있습니다. 이는 모델이 훈련을 통해 특정 지식을 효과적으로 내재화했음을 나타냅니다.\n",
      "   - **근거 :** \"...the accumulated log probability of the knowledge will be high enough to generate the knowledge as the decoding output of the model.\"\n",
      "\n",
      "답변 요약 \n",
      ": 이 논문은 LLM의 사실적 지식 습득 과정을 분석하기 위해 로그 확률을 평가하는 방법을 제시합니다. 잘 알려진 사실들은 학습 가능성 임계값보다 짧은 훈련 단계 간격으로 모델에 제공되어, 초기 훈련 단계에서부터 모델의 출력에 반영됩니다. 이러한 지식의 습득은 모델의 상위 k 출력 시퀀스 생성에서 나타나며, 누적된 로그 확률이 충분히 높아지면 모델은 해당 지식을 디코딩 출력으로 생성할 수 있습니다. 이로 인해 LLM의 훈련 과정에서 지식 습득의 메커니즘을 이해하는 데 중요한 통찰을 제공합니다.\n",
      "\n",
      "인용 논문 제목 (Title): Are emergent abilities of large language models a mirage?\n",
      "\n",
      "해당 논문은 LLM의 사실적 지식 습득 과정을 로그 확률을 통해 세밀하게 분석함으로써, 모델이 훈련 초기 단계에서부터 잘 알려진 사실을 효과적으로 내재화할 수 있음을 보여줍니다. 특히, 학습 가능성 임계값보다 짧은 훈련 단계 간격으로 제공된 정보가 모델의 출력에 반영되며, 누적된 로그 확률이 충분히 높아질 경우 해당 지식을 디코딩 출력으로 생성할 수 있다는 점은 LLM의 훈련 메커니즘에 대한 중요한 통찰을 제공합니다. 이러한 발견은 LLM의 사실적 지식 습득에 대한 이해를 심화시키고, 향후 연구 방향에 기여할 수 있습니다.\n",
      "##########\n",
      "\n",
      "인용 논문 제목 (Title): <<To repeat or not to repeat: Insights from scaling llm under token-crisis>>\n",
      "\n",
      "1. **질문 :** 데이터셋 중복 제거의 중요성은 무엇인가요?\n",
      "   - **답변 :** 데이터셋 중복 제거는 모델 성능 향상에 중요한 요소로 관찰되고 있습니다. 중복된 데이터는 모델이 특정 패턴에 과적합(overfitting)하게 만들 수 있으며, 이는 모델의 일반화 능력을 저하시킬 수 있습니다. 따라서, 데이터셋의 중복을 제거함으로써 모델이 더 다양한 데이터를 학습하고, 더 나은 성능을 발휘할 수 있도록 하는 것이 중요합니다.\n",
      "   - **근거 :** \"it is widely observed that deduplication of pretraining data is an important factor in improving model performance [29, 52].\"\n",
      "\n",
      "2. **질문 :** 데이터셋 중복 제거의 중요성을 설명할 수 있나요?\n",
      "   - **답변 :** 데이터셋 중복 제거는 모델이 다양한 데이터를 학습하도록 도와주며, 이는 모델의 일반화 능력을 향상시킵니다. 중복된 데이터는 모델이 특정 데이터에 과도하게 적응하게 만들어, 새로운 데이터에 대한 성능 저하를 초래할 수 있습니다. 따라서, 중복 제거는 모델의 성능을 높이는 데 필수적입니다.\n",
      "   - **근거 :** \"the importance of dataset deduplication can be explained.\"\n",
      "\n",
      "답변 요약 \n",
      ": 데이터셋 중복 제거는 대규모 언어 모델(LLM)의 성능 향상에 필수적인 요소로, 중복된 데이터는 모델이 특정 패턴에 과적합하게 만들어 일반화 능력을 저하시킬 수 있습니다. 따라서, 중복 제거를 통해 모델이 다양한 데이터를 학습하고 더 나은 성능을 발휘할 수 있도록 하는 것이 중요합니다. 연구에 따르면, 데이터셋 중복 제거는 모델 성능을 개선하는 중요한 요소로 관찰되며, 이는 모델이 새로운 데이터에 대해 더 잘 일반화할 수 있도록 돕습니다. 이러한 이유로 데이터셋의 중복을 제거하는 것은 LLM의 효과적인 학습을 위해 필수적입니다.\n",
      "\n",
      "해당 논문 \"How Do Large Language Models Acquire Factual Knowledge During Pretraining?\"은 인용 논문에서 강조된 데이터셋 중복 제거의 중요성을 바탕으로 LLM의 사실적 지식 습득 메커니즘을 심층적으로 탐구합니다. 연구 결과, 중복된 데이터가 모델의 과적합을 초래하고 일반화 능력을 저하시킨다는 점을 확인하며, 이는 LLM이 다양한 데이터를 효과적으로 학습하는 데 필수적임을 강조합니다. 또한, 중복 제거가 모델의 성능 향상에 기여하는 방식에 대한 구체적인 메커니즘을 제시함으로써, LLM의 훈련 과정에서의 지식 습득과 망각의 역학을 이해하는 데 기여합니다. 이러한 통찰은 LLM의 훈련 데이터 구성에 대한 새로운 방향성을 제시합니다.\n",
      "##########\n",
      "\n",
      "인용 논문 제목 (Title): Language models are few-shot learners\n",
      "\n",
      "1. **질문 :** 최근의 사전 훈련 코퍼스는 철저하게 중복 제거되었는가?\n",
      "   - **답변 :** 최근의 사전 훈련 코퍼스는 중복 제거가 철저히 이루어졌으며, 이는 모델 성능을 향상시키는 데 기여하는 것으로 널리 관찰되고 있다. 데이터 중복 제거는 모델이 더 다양한 정보를 학습할 수 있도록 하여 성능을 높이는 데 중요한 역할을 한다.\n",
      "   - **근거 :** \"Recent pretraining corpora are thoroughly deduplicated, as it is widely observed that data deduplication can improve model performance.\"\n",
      "\n",
      "2. **질문 :** 최근 LLM(대형 언어 모델)에 대한 관심이 급증하고 있는가?\n",
      "   - **답변 :** 최근 LLM에 대한 관심이 급증하고 있으며, 이는 다양한 비전-언어 작업에서의 성능 향상과 관련이 있다. LLM은 자연어 처리 및 비전-언어 이해 작업에서 강력한 성능을 보여주고 있다.\n",
      "   - **근거 :** \"Recently, there has been a surge in interest in LLMs.\"\n",
      "\n",
      "3. **질문 :** 최근의 사전 훈련 코퍼스는 철저하게 중복 제거되었는가?\n",
      "   - **답변 :** 최근의 사전 훈련 코퍼스는 중복 제거가 철저히 이루어졌으며, 이는 모델 성능을 향상시키는 데 기여하는 것으로 널리 관찰되고 있다. 데이터 중복 제거는 모델이 더 다양한 정보를 학습할 수 있도록 하여 성능을 높이는 데 중요한 역할을 한다.\n",
      "   - **근거 :** \"Recent pretraining corpora are thoroughly deduplicated, as it is widely observed that data deduplication can improve model performance.\"\n",
      "\n",
      "답변 요약: 최근의 연구에 따르면, 사전 훈련 코퍼스는 철저하게 중복 제거되어 있으며, 이는 모델 성능 향상에 기여하는 것으로 나타났다. 데이터 중복 제거는 모델이 다양한 정보를 학습할 수 있도록 도와주며, 이는 LLM에 대한 관심이 급증하는 배경 중 하나로 작용하고 있다. LLM은 비전-언어 작업에서 강력한 성능을 보여주고 있으며, 이러한 경향은 앞으로도 계속될 것으로 예상된다.\n",
      "\n",
      "인용 논문 제목 (Title): Language models are few-shot learners\n",
      "\n",
      "해당 논문은 LLM의 사전 훈련 과정에서의 사실적 지식 습득 메커니즘을 탐구하며, 중복 제거된 데이터의 중요성을 강조한다. 인용 논문에서 언급된 바와 같이, 중복 제거는 모델이 다양한 정보를 학습하도록 도와주어 성능 향상에 기여한다. 본 연구는 이러한 점을 바탕으로, 중복된 훈련 데이터가 사실적 지식의 망각을 가속화한다는 사실을 발견하였다. 이는 LLM의 성능 저하와 관련된 최근 관찰을 설명하는 데 기여하며, LLM의 훈련 데이터 구성 방식에 대한 새로운 통찰을 제공한다.\n",
      "##########\n",
      "\n",
      "### 인용 논문 제목 (Title): Language models as knowledge bases?\n",
      "\n",
      "1. **질문 :** 최근 연구들은 LLM이 사전 훈련 데이터에서 상당한 사실적 지식을 포착할 수 있음을 보여주었다 [14, 36, 40].\n",
      "   - **답변 :** 최근 연구들은 대형 언어 모델(LLM)이 사전 훈련 데이터에서 상당한 사실적 지식을 포착할 수 있음을 입증했습니다. LLM은 정보 검색 모델보다 지식 집약적인 작업에서 더 나은 성능을 보이며, 생성된 지식의 사실성은 다소 낮지만, 이는 하위 작업의 성능에 큰 영향을 미치지 않는 것으로 나타났습니다. \n",
      "   - **근거 :** \"LLM-generated knowledge surpasses retrieved knowledge in most evaluation perspectives, while it actually suffers from the factuality issue as expected.\"\n",
      "\n",
      "2. **질문 :** LLM의 매개변수에 인코딩된 지식에 대한 광범위한 연구가 진행되었다 [36, 40].\n",
      "   - **답변 :** LLM의 매개변수에 인코딩된 지식에 대한 연구는 LLM이 생성하는 지식의 질과 신뢰성을 평가하는 데 중요한 역할을 합니다. 연구 결과, LLM이 생성한 지식은 정보 검색 모델보다 더 유용하고 관련성이 높지만, 사실성 문제는 여전히 존재합니다. \n",
      "   - **근거 :** \"Despite obtaining lower factuality than retrieved knowledge, generated knowledge contributes more to the factuality of downstream tasks.\"\n",
      "\n",
      "### 답변 요약 (Summary of Answers)\n",
      "최근 연구들은 대형 언어 모델(LLM)이 사전 훈련 데이터에서 상당한 사실적 지식을 포착할 수 있음을 보여주고 있습니다. LLM은 정보 검색 모델보다 지식 집약적인 작업에서 더 나은 성능을 발휘하며, 생성된 지식의 사실성은 다소 낮지만 하위 작업의 성능에 큰 영향을 미치지 않는 것으로 나타났습니다. 또한, LLM의 매개변수에 인코딩된 지식에 대한 연구는 LLM이 생성하는 지식의 질과 신뢰성을 평가하는 데 중요한 역할을 하며, LLM이 생성한 지식은 정보 검색 모델보다 더 유용하고 관련성이 높지만 여전히 사실성 문제를 안고 있습니다. 이러한 연구 결과는 LLM을 지식 생성기로 활용하는 데 있어 중요한 통찰을 제공합니다.\n",
      "\n",
      "해당 논문 \"How Do Large Language Models Acquire Factual Knowledge During Pretraining?\"은 인용 논문에서 제기된 LLM의 사실적 지식 포착 능력과 관련된 질문에 대한 심층적인 분석을 통해 연구를 발전시켰습니다. 특히, LLM이 사전 훈련 데이터에서 지식을 어떻게 획득하고 유지하는지를 탐구하며, 더 많은 데이터로 훈련해도 사실적 지식의 획득에 유의미한 개선이 없음을 밝혀냈습니다. 또한, LLM의 매개변수에 인코딩된 지식의 질과 신뢰성에 대한 기존 연구를 바탕으로, 훈련 단계와 기억 상실 간의 관계를 규명하고, 대량의 중복 데이터를 사용할 경우 더 빠른 기억 상실이 발생한다는 점을 강조했습니다. 이러한 통찰은 LLM의 지식 생성 및 활용에 대한 이해를 심화시키는 데 기여합니다.\n",
      "##########\n",
      "\n",
      "인용 논문 제목 (Title): Dolma: An open corpus of three trillion tokens for language model pretraining research\n",
      "\n",
      "1. **질문 :** 최근의 사전 훈련 코퍼스는 철저하게 중복 제거가 이루어졌다고 하는데, 데이터 중복 제거가 모델 성능을 향상시킬 수 있다는 것이 널리 관찰되고 있다. \n",
      "   - **답변 :** 데이터 중복 제거는 모델 훈련 시 토큰 효율성을 높이는 데 효과적이며, 이는 많은 연구에서 입증되었다. Dolma에서는 세 가지 단계의 중복 제거를 수행하여 데이터의 품질을 높였다. \n",
      "   - **근거 :** \"Deduplication of pretraining data has been shown to be effective for improving token efficiency during model training (Lee et al., 2022; Abbas et al., 2023; Tirumala et al., 2023).\"\n",
      "\n",
      "2. **질문 :** OLMo의 중간 체크포인트를 재개하여 OLMo의 사전 훈련 데이터(Dolma v1.5)를 사용하고, 매 100 훈련 단계마다 FICTIONAL KNOWLEDGE 데이터셋의 지식을 주입한다고 하는데, 이는 어떤 방식으로 이루어지는가?\n",
      "   - **답변 :** OLMo의 중간 체크포인트를 재개할 때, 원래의 사전 훈련 배치의 일부를 FICTIONAL KNOWLEDGE 데이터셋의 지식으로 교체하여 사실적 지식을 주입하는 방식으로 진행된다. 이는 모델이 훈련 중에 새로운 정보를 지속적으로 학습할 수 있도록 돕는다.\n",
      "   - **근거 :** \"we inject factual knowledge every 100 training steps by replacing a part of original pretraining batch with the injected knowledge of the FICTIONAL KNOWLEDGE dataset.\"\n",
      "\n",
      "답변 요약 \n",
      ": Dolma는 세 가지 트릴리언 토큰으로 구성된 오픈 코퍼스로, 최근의 사전 훈련 코퍼스에서 중복 제거가 모델 성능을 향상시키는 데 효과적이라는 연구 결과를 바탕으로, 세 가지 단계의 중복 제거를 통해 데이터 품질을 높였다. 또한 OLMo의 중간 체크포인트를 재개하여 FICTIONAL KNOWLEDGE 데이터셋의 지식을 주입하는 방식으로 훈련이 이루어지며, 이는 모델이 새로운 정보를 지속적으로 학습할 수 있도록 돕는다. 이러한 접근은 언어 모델의 성능을 극대화하는 데 기여할 것으로 기대된다.\n",
      "\n",
      "인용 논문 제목 (Title): Dolma: An open corpus of three trillion tokens for language model pretraining research\n",
      "\n",
      "해당 논문은 LLM의 사전 훈련 과정에서 데이터 중복 제거가 모델 성능 향상에 미치는 영향을 심층적으로 분석하며, Dolma의 세 가지 단계의 중복 제거를 통해 데이터 품질을 높이는 방법을 제시한다. 또한, OLMo의 중간 체크포인트를 활용하여 FICTIONAL KNOWLEDGE 데이터셋의 지식을 주입하는 방식을 통해 모델이 새로운 정보를 지속적으로 학습할 수 있도록 지원한다. 이러한 연구는 LLM의 사실적 지식 습득 메커니즘을 이해하는 데 기여하며, 모델의 성능을 극대화하는 데 중요한 통찰을 제공한다.\n",
      "##########\n",
      "\n",
      "인용 논문 제목 (Title): An empirical study of catastrophic forgetting in large language models during continual fine-tuning\n",
      "\n",
      "1. **질문 :** 다양한 LLM 훈련의 측면에서 기억 상실의 기하급수적 경향이 보고되었는데, 여기에는 사전 훈련에서의 암기와 지속적 학습에서의 작업 성능이 포함된다. \n",
      "   - **답변 :** 연구에 따르면, 대형 언어 모델(LLM)에서 기억 상실 현상은 일반적으로 관찰되며, 모델의 크기가 증가할수록 기억 상실의 심각성이 증가하는 경향이 있다. 이는 초기 성능이 더 높은 대형 모델이 새로운 작업에 적합하기 위해 더 많은 매개변수 조정을 필요로 하기 때문이다.\n",
      "   - **근거 :** \"Our findings reveal that the forgetting problem is generally present in LLMs... as the model scale increases, the severity of forgetting intensifies.\"\n",
      "\n",
      "2. **질문 :** 여러 연구가 LLM의 훈련 역학을 조사했으며, 특히 훈련 중 어떻게 발전하는지를 다루었다. \n",
      "   - **답변 :** LLM의 훈련 역학에 대한 연구는 모델이 훈련 중에 어떻게 변화하는지를 분석하며, 이는 지속적 학습에서의 기억 상실 문제와 밀접한 관련이 있다. 연구 결과는 LLM이 지속적 훈련을 통해 일반 지식을 잃는 경향이 있음을 보여준다.\n",
      "   - **근거 :** \"We provide an initial research evidence that the CF problem generally exists in the continual instruction tuning process for different models...\"\n",
      "\n",
      "3. **질문 :** 훈련 단계와 습득한 사실적 지식의 기억 상실 간에는 거듭제곱 법칙 관계가 있다. \n",
      "   - **답변 :** 연구 결과는 훈련 단계가 증가함에 따라 LLM의 기억 상실이 더욱 심화된다는 것을 보여준다. 이는 모델이 새로운 작업에 적합하기 위해 더 많은 매개변수 조정을 필요로 하기 때문이며, 이로 인해 이전에 학습한 지식이 잊혀지는 경향이 있다.\n",
      "   - **근거 :** \"The performance gradually decreases as we continually tune the model with instruction tasks... the general knowledge suffers more significant forgetting.\"\n",
      "\n",
      "답변 요약 \n",
      ": 이 연구는 대형 언어 모델(LLM)에서 지속적 훈련 중 발생하는 기억 상실 현상에 대한 실증적 분석을 제공한다. 연구 결과, LLM은 훈련 단계가 증가할수록 기억 상실이 심화되며, 이는 모델의 초기 성능이 높을수록 더욱 두드러진다. 또한, LLM의 훈련 역학을 분석한 결과, 지속적 훈련 과정에서 일반 지식이 잊혀지는 경향이 있음을 확인하였다. 특히, 디코더 전용 모델인 BLOOMZ가 인코더-디코더 모델인 mT0보다 더 나은 지식 유지 능력을 보이는 것으로 나타났다. 마지막으로, 일반 지침 조정이 기억 상실 문제를 완화하는 데 도움이 될 수 있음을 시사한다. 이러한 결과는 LLM의 지속적 훈련에서 기억 상실 문제를 해결하기 위한 추가 연구의 필요성을 강조한다.\n",
      "\n",
      "인용 논문 제목 (Title): An empirical study of catastrophic forgetting in large language models during continual fine-tuning\n",
      "\n",
      "해당 논문은 대형 언어 모델(LLM)의 사전 훈련 과정에서 사실적 지식의 습득과 기억 상실 간의 관계를 심층적으로 분석함으로써, 인용 논문에서 제기된 기억 상실 문제를 발전시켰다. 특히, 훈련 단계가 증가함에 따라 기억 상실이 심화된다는 점을 강조하며, 이는 모델의 초기 성능이 높을수록 더욱 두드러진다는 사실을 확인하였다. 또한, LLM의 훈련 역학을 통해 지속적 훈련에서 일반 지식이 잊혀지는 경향을 밝혀내어, 기억 상실 문제 해결을 위한 새로운 연구 방향을 제시하였다. 이러한 통찰은 LLM의 훈련 및 성능 최적화에 중요한 기초 자료로 작용할 수 있다.\n",
      "##########\n",
      "\n",
      "인용 논문 제목 (Title): How much knowledge can you pack into the parameters of a language model?\n",
      "\n",
      "1. **질문 :** 최근 연구들은 LLM이 사전 훈련 데이터에서 상당한 사실적 지식을 포착할 수 있음을 보여주었다 [14, 36, 40].\n",
      "   - **답변 :** 최근 연구들은 대규모 언어 모델(LLM)이 비구조화된 텍스트로 훈련되었을 때, 사전 훈련 데이터에서 사실적 지식을 효과적으로 저장하고 검색할 수 있음을 보여주었다. 이러한 모델들은 자연어 쿼리를 통해 지식을 검색할 수 있으며, 이는 정보가 비구조화된 데이터에서 축적되기 때문에 가능하다. 이 연구는 LLM이 사전 훈련 중 내재화한 지식을 기반으로 질문에 답할 수 있는 능력을 평가하였다.\n",
      "   - **근거 :** \"It has also recently been observed that these models can internalize a sort of implicit 'knowledge base' after pre-training.\"\n",
      "\n",
      "2. **질문 :** LLM의 매개변수에 인코딩된 지식에 대한 광범위한 연구가 진행되었다 [36, 40].\n",
      "   - **답변 :** LLM의 매개변수에 인코딩된 지식에 대한 연구는 주로 모델이 사전 훈련 중 저장한 정보의 범위를 이해하고, 이러한 정보가 실제 질문 응답 작업에서 어떻게 활용되는지를 평가하는 데 초점을 맞추었다. 연구자들은 모델이 외부 지식에 접근하지 않고도 질문에 답할 수 있는 능력을 평가하여, 모델의 매개변수에 얼마나 많은 지식이 저장되어 있는지를 측정하였다.\n",
      "   - **근거 :** \"By feeding the model the input question alone, we can determine how much knowledge it has stored in its parameters while measuring its performance on a useful real-world problem.\"\n",
      "\n",
      "답변 요약 \n",
      ": 최근 연구들은 대규모 언어 모델(LLM)이 비구조화된 텍스트로 훈련되었을 때, 상당한 사실적 지식을 저장하고 검색할 수 있는 능력을 보여주었다. 이러한 모델들은 사전 훈련 중 내재화한 지식을 기반으로 질문에 답할 수 있으며, 이는 비구조화된 데이터에서 축적된 정보 덕분이다. 또한, LLM의 매개변수에 인코딩된 지식에 대한 연구는 모델이 외부 지식에 접근하지 않고도 질문에 답할 수 있는 능력을 평가하는 데 중점을 두었다. 이러한 연구들은 LLM이 실제 질문 응답 작업에서 얼마나 많은 지식을 저장하고 활용할 수 있는지를 측정하는 데 기여하고 있다.\n",
      "\n",
      "인용 논문 제목 (Title): How much knowledge can you pack into the parameters of a language model?\n",
      "\n",
      "해당 논문은 대규모 언어 모델(LLM)이 사전 훈련 중 비구조화된 텍스트에서 상당한 사실적 지식을 저장하고 검색할 수 있는 능력을 강조하며, 이러한 지식이 질문 응답 작업에서 어떻게 활용되는지를 평가하는 데 중점을 두었다. 본 연구는 LLM의 사실적 지식 습득 메커니즘을 심층적으로 분석하여, 더 많은 데이터로 훈련하더라도 지식의 유지에 큰 개선이 없음을 발견하고, 훈련 단계와 기억 상실 간의 관계를 규명하였다. 이를 통해 LLM의 지식 저장 능력과 외부 지식 접근 없이 질문에 답하는 능력 간의 상관관계를 명확히 하여, LLM의 성능을 이해하는 데 기여하였다.\n",
      "##########\n",
      "\n",
      "인용 논문 제목 (Title): Does fine-tuning llms on new knowledge encourage hallucinations?\n",
      "\n",
      "1. **질문 :** [44]와 [46]은 언어 모델 사전 훈련에서 기억의 동역학에 초점을 맞췄다.\n",
      "   - **답변 :** 이 연구는 언어 모델의 사전 훈련 과정에서 기억의 동역학을 분석하며, 모델이 어떻게 정보를 기억하고 활용하는지를 탐구한다. 특히, 모델이 새로운 지식을 통합하는 데 어려움을 겪는다는 점을 강조한다.\n",
      "   - **근거 :** \"We demonstrate that large language models struggle to acquire new factual knowledge through fine-tuning...\"\n",
      "\n",
      "2. **질문 :** 여러 연구들이 LLM의 훈련 동역학을 조사했으며, 특히 훈련 중 어떻게 진화하는지를 다루었다 [12, 18, 22, 32, 33, 45, 51].\n",
      "   - **답변 :** LLM의 훈련 동역학에 대한 연구는 모델이 훈련 중에 어떻게 변화하는지를 분석하며, 특히 새로운 지식을 통합하는 과정에서의 어려움을 다룬다.\n",
      "   - **근거 :** \"We find that fine-tuning examples that introduce new knowledge are learned slowly...\"\n",
      "\n",
      "3. **질문 :** 사전 훈련 중 지식 주입에 대해, LLM이 기억과 일반화 측면에서 사실적 지식을 어떻게 습득하고 유지하는지를 탐구한다.\n",
      "   - **답변 :** LLM은 사전 훈련 중에 사실적 지식을 습득하고 이를 유지하는 데 어려움을 겪으며, 이는 기억과 일반화의 관점에서 분석된다.\n",
      "   - **근거 :** \"We explore how LLMs acquire and retain factual knowledge in terms of memorization and generalization...\"\n",
      "\n",
      "4. **질문 :** 그림 5의 추정된 x-절편은 훈련을 통해 습득한 사실적 지식의 완전한 손실로 이어지는 추가 훈련 토큰의 수를 나타낸다.\n",
      "   - **답변 :** x-절편은 모델이 훈련을 통해 습득한 사실적 지식이 완전히 소실되기 위해 필요한 추가 훈련 토큰의 수를 나타내며, 이는 모델의 기억 능력을 평가하는 데 중요한 지표가 된다.\n",
      "   - **근거 :** \"The estimated x-intercepts in Figure 5 represent the number of additional training tokens...\"\n",
      "\n",
      "5. **질문 :** 그러나 지식 관찰 시 로그 확률의 즉각적인 개선량은 더 큰 모델에 대해 증가하지만, 사전 훈련 진행 중에는 크게 증가하지 않는다.\n",
      "   - **답변 :** 모델의 크기가 커질수록 지식 관찰 시 로그 확률의 즉각적인 개선량은 증가하지만, 사전 훈련의 진행 과정에서는 그 증가폭이 크지 않다.\n",
      "   - **근거 :** \"the amount of immediate improvement in log probability upon observation of the knowledge increases for larger models...\"\n",
      "\n",
      "6. **질문 :** 우리는 LLM이 비인기 지식을 습득하는 데 어려움을 겪는다고 가정한다. 이는 충분한 노출이 필요하기 때문이다.\n",
      "   - **답변 :** LLM은 비인기 지식을 습득하는 데 어려움을 겪으며, 이는 학습 가능성의 임계값보다 짧은 간격으로 사실적 지식에 충분히 노출되어야 가능하다.\n",
      "   - **근거 :** \"we hypothesize that LLMs struggle to acquire unpopular knowledge because they need sufficient exposure...\"\n",
      "\n",
      "답변 요약 \n",
      ": 이 연구는 LLM이 새로운 사실적 지식을 통합하는 과정에서의 어려움과 그로 인해 발생하는 환각 현상에 대해 다룬다. LLM은 사전 훈련을 통해 사실적 지식을 습득하지만, 새로운 지식을 추가하는 과정에서 느린 학습 속도와 함께 기존 지식의 활용이 저하되는 경향이 있다. 특히, 비인기 지식의 습득이 어려운 이유는 학습 가능성의 임계값보다 짧은 간격으로 충분한 노출이 필요하기 때문이다. 이러한 결과는 LLM의 훈련 동역학과 기억 능력에 대한 중요한 통찰을 제공하며, 새로운 지식을 주입하는 것이 환각을 유발할 수 있음을 시사한다.\n",
      "\n",
      "인용 논문 제목 (Title): <<Does fine-tuning llms on new knowledge encourage hallucinations?>>\n",
      "\n",
      "해당 논문은 LLM이 새로운 사실적 지식을 통합하는 과정에서의 어려움과 그로 인해 발생하는 환각 현상에 대한 심층적인 분석을 통해 연구를 발전시켰다. 특히, LLM이 사전 훈련 중에 습득한 지식을 유지하는 데 어려움을 겪으며, 새로운 지식을 추가하는 과정에서 느린 학습 속도와 기존 지식의 활용 저하가 발생한다는 점을 강조하였다. 또한, 비인기 지식의 습득이 어려운 이유로 충분한 노출이 필요하다는 가설을 제시함으로써, LLM의 훈련 동역학과 기억 능력에 대한 중요한 통찰을 제공하고, 새로운 지식 주입이 환각을 유발할 수 있음을 시사하였다. 이러한 연구 결과는 LLM의 사실적 지식 습득 메커니즘에 대한 이해를 심화시키는 데 기여한다.\n",
      "##########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"result/reference_qna.json\", 'r') as f:\n",
    "    reference_qna = json.load(f)\n",
    "\n",
    "for key, value_dict in reference_qna.items():\n",
    "    print(value_dict['Summary'])\n",
    "    print()\n",
    "    print(value_dict['Summary_QnA'])\n",
    "    print(\"##########\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107714/2094099114.py:28: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x=\"title\", y=\"citation_score\", data=df, palette=\"coolwarm\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# JSON 파일 로드\n",
    "with open(\"result/reference_count.json\", 'r') as f:\n",
    "    reference_count = json.load(f)\n",
    "\n",
    "# 최대 citation count 구하기\n",
    "for key, value_dict in reference_count.items():\n",
    "    max_count = int(value_dict['Counter'])\n",
    "    break\n",
    "\n",
    "# Citation Score 계산\n",
    "nums = 11\n",
    "score_dict = {}\n",
    "for key, value_dict in reference_count.items():\n",
    "    score_dict[value_dict['Title'][:15]] = int(value_dict['Counter']) / max_count\n",
    "\n",
    "df = pd.DataFrame(list(score_dict.items())[:nums], columns=[\"title\", \"citation_score\"])\n",
    "\n",
    "# 🌟 Seaborn 스타일 설정\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# 🎨 Seaborn 막대 그래프 그리기 (색상 변경)\n",
    "plt.figure(figsize=(12, 7))\n",
    "ax = sns.barplot(x=\"title\", y=\"citation_score\", data=df, palette=\"coolwarm\")\n",
    "\n",
    "# X축 라벨 90도 회전 & 폰트 크기 조정\n",
    "plt.xticks(rotation=90, fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "\n",
    "# 라벨 추가\n",
    "plt.xlabel(\"Title\", fontsize=13, fontweight='bold')\n",
    "plt.ylabel(\"Citation Score\", fontsize=13, fontweight='bold')\n",
    "plt.title(\"Citation Score of References\", fontsize=15, fontweight='bold')\n",
    "\n",
    "# 막대 위에 값 표시 (숫자)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\",\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=10, fontweight=\"bold\", color=\"black\")\n",
    "\n",
    "# 여백 조정\n",
    "plt.tight_layout()\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile</th>\n",
       "      <th>citation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scaling laws for neural language models</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deduplicating training data makes language mod...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Memorization without overfitting: Analyzing th...</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are emergent abilities of large language model...</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To repeat or not to repeat: Insights from scal...</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Language models are few-shot learners</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Language models as knowledge bases?</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dolma: An open corpus of three trillion tokens...</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>An empirical study of catastrophic forgetting ...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How much knowledge can you pack into the param...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Does fine-tuning llms on new knowledge encoura...</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Large language models struggle to learn long-t...</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Physics of language models: Part 3.2, knowledg...</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Llama 2: Open foundation and fine-tuned chat m...</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gpt-4 technical report</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Physics of language models: Part 3.1, knowledg...</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pythia: A suite for analyzing large language m...</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Extracting training data from large language m...</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sudden drops in the loss: Syntax acquisition, ...</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Palm: Scaling language modeling with pathways</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Analyzing commonsense emergence in few-shot kn...</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Entity cloze by date: What lms know about unse...</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Emergent abilities of large language models</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Critical data size of language models from a g...</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A closer look at memorization in deep networks</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Transformer feed-forward layers are key-value ...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The bigscience roots corpus: A 1.6 tb composit...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>When not to trust language models: Investigati...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Exploring the limits of transfer learning with...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Memorisation versus generalisation in pre-trai...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>D4: Improving llm pretraining via document de-...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Llama: Open and efficient foundation language ...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Semdedup: Data-efficient learning at web-scale...</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Probing across time: What does RoBERTa know an...</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Anatomy of catastrophic forgetting: Hidden rep...</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Emergent and predictable memorization in large...</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Tracing knowledge in language models back to t...</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Knowledge neurons in pretrained transformers</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Does learning require memorization? a short ta...</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Dissecting recall of factual associations in a...</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>How pre-trained language models capture factua...</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Grokking: Generalization beyond overfitting on...</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Quantifying memorization across neural languag...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>The surprising simplicity of the early-time le...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Training trajectories of language models acros...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tile  citation_score\n",
       "0             Scaling laws for neural language models        1.000000\n",
       "1   Deduplicating training data makes language mod...        0.750000\n",
       "2   Memorization without overfitting: Analyzing th...        0.583333\n",
       "3   Are emergent abilities of large language model...        0.416667\n",
       "4   To repeat or not to repeat: Insights from scal...        0.416667\n",
       "5               Language models are few-shot learners        0.375000\n",
       "6                 Language models as knowledge bases?        0.375000\n",
       "7   Dolma: An open corpus of three trillion tokens...        0.375000\n",
       "8   An empirical study of catastrophic forgetting ...        0.333333\n",
       "9   How much knowledge can you pack into the param...        0.333333\n",
       "10  Does fine-tuning llms on new knowledge encoura...        0.291667\n",
       "11  Large language models struggle to learn long-t...        0.291667\n",
       "12  Physics of language models: Part 3.2, knowledg...        0.250000\n",
       "13  Llama 2: Open foundation and fine-tuned chat m...        0.250000\n",
       "14                             Gpt-4 technical report        0.208333\n",
       "15  Physics of language models: Part 3.1, knowledg...        0.208333\n",
       "16  Pythia: A suite for analyzing large language m...        0.208333\n",
       "17  Extracting training data from large language m...        0.208333\n",
       "18  Sudden drops in the loss: Syntax acquisition, ...        0.208333\n",
       "19      Palm: Scaling language modeling with pathways        0.208333\n",
       "20  Analyzing commonsense emergence in few-shot kn...        0.208333\n",
       "21  Entity cloze by date: What lms know about unse...        0.208333\n",
       "22        Emergent abilities of large language models        0.208333\n",
       "23  Critical data size of language models from a g...        0.208333\n",
       "24     A closer look at memorization in deep networks        0.166667\n",
       "25  Transformer feed-forward layers are key-value ...        0.166667\n",
       "26                                         Mistral 7b        0.166667\n",
       "27  The bigscience roots corpus: A 1.6 tb composit...        0.166667\n",
       "28  When not to trust language models: Investigati...        0.166667\n",
       "29  Exploring the limits of transfer learning with...        0.166667\n",
       "30  Memorisation versus generalisation in pre-trai...        0.166667\n",
       "31  D4: Improving llm pretraining via document de-...        0.166667\n",
       "32  Llama: Open and efficient foundation language ...        0.166667\n",
       "33  Semdedup: Data-efficient learning at web-scale...        0.125000\n",
       "34  Probing across time: What does RoBERTa know an...        0.125000\n",
       "35  Anatomy of catastrophic forgetting: Hidden rep...        0.125000\n",
       "36  Emergent and predictable memorization in large...        0.083333\n",
       "37  Tracing knowledge in language models back to t...        0.041667\n",
       "38       Knowledge neurons in pretrained transformers        0.041667\n",
       "39  Does learning require memorization? a short ta...        0.041667\n",
       "40  Dissecting recall of factual associations in a...        0.041667\n",
       "41  How pre-trained language models capture factua...        0.041667\n",
       "42  Grokking: Generalization beyond overfitting on...        0.041667\n",
       "43  Quantifying memorization across neural languag...        0.000000\n",
       "44  The surprising simplicity of the early-time le...        0.000000\n",
       "45  Training trajectories of language models acros...        0.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scaling laws for neural language models',\n",
       " 'Deduplicating training data makes language models better',\n",
       " 'Memorization without overfitting: Analyzing the training dynamics of large language models',\n",
       " 'Are emergent abilities of large language models a mirage?',\n",
       " 'To repeat or not to repeat: Insights from scaling llm under token-crisis',\n",
       " 'Language models are few-shot learners',\n",
       " 'Language models as knowledge bases?',\n",
       " 'Dolma: An open corpus of three trillion tokens for language model pretraining research',\n",
       " 'An empirical study of catastrophic forgetting in large language models during continual fine-tuning',\n",
       " 'How much knowledge can you pack into the parameters of a language model?',\n",
       " 'Does fine-tuning llms on new knowledge encourage hallucinations?',\n",
       " 'Large language models struggle to learn long-tail knowledge',\n",
       " 'Physics of language models: Part 3.2, knowledge manipulation',\n",
       " 'Llama 2: Open foundation and fine-tuned chat models',\n",
       " 'Gpt-4 technical report',\n",
       " 'Physics of language models: Part 3.1, knowledge storage and extraction',\n",
       " 'Pythia: A suite for analyzing large language models across training and scaling',\n",
       " 'Extracting training data from large language models',\n",
       " 'Sudden drops in the loss: Syntax acquisition, phase transitions, and simplicity bias in MLMs',\n",
       " 'Palm: Scaling language modeling with pathways',\n",
       " 'Analyzing commonsense emergence in few-shot knowledge models',\n",
       " 'Entity cloze by date: What lms know about unseen entities',\n",
       " 'Emergent abilities of large language models',\n",
       " 'Critical data size of language models from a grokking perspective',\n",
       " 'A closer look at memorization in deep networks',\n",
       " 'Transformer feed-forward layers are key-value memories',\n",
       " 'Mistral 7b',\n",
       " 'The bigscience roots corpus: A 1.6 tb composite multilingual dataset',\n",
       " 'When not to trust language models: Investigating effectiveness of parametric and non-parametric memories',\n",
       " 'Exploring the limits of transfer learning with a unified text-to-text transformer',\n",
       " 'Memorisation versus generalisation in pre-trained language models',\n",
       " 'D4: Improving llm pretraining via document de-duplication and diversification',\n",
       " 'Llama: Open and efficient foundation language models',\n",
       " 'Semdedup: Data-efficient learning at web-scale through semantic deduplication',\n",
       " 'Probing across time: What does RoBERTa know and when?',\n",
       " 'Anatomy of catastrophic forgetting: Hidden representations and task semantics',\n",
       " 'Emergent and predictable memorization in large language models',\n",
       " 'Tracing knowledge in language models back to the training data',\n",
       " 'Knowledge neurons in pretrained transformers',\n",
       " 'Does learning require memorization? a short tale about a long tail',\n",
       " 'Dissecting recall of factual associations in auto-regressive language models',\n",
       " 'How pre-trained language models capture factual knowledge? a causal-inspired analysis',\n",
       " 'Grokking: Generalization beyond overfitting on small algorithmic datasets',\n",
       " 'Quantifying memorization across neural language models',\n",
       " 'The surprising simplicity of the early-time learning dynamics of neural networks',\n",
       " 'Training trajectories of language models across scales']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.75,\n",
       " 0.5833333333333334,\n",
       " 0.4166666666666667,\n",
       " 0.4166666666666667,\n",
       " 0.375,\n",
       " 0.375,\n",
       " 0.375,\n",
       " 0.3333333333333333,\n",
       " 0.3333333333333333,\n",
       " 0.2916666666666667,\n",
       " 0.2916666666666667,\n",
       " 0.25,\n",
       " 0.25,\n",
       " 0.20833333333333334,\n",
       " 0.20833333333333334,\n",
       " 0.20833333333333334,\n",
       " 0.20833333333333334,\n",
       " 0.20833333333333334,\n",
       " 0.20833333333333334,\n",
       " 0.20833333333333334,\n",
       " 0.20833333333333334,\n",
       " 0.20833333333333334,\n",
       " 0.20833333333333334,\n",
       " 0.16666666666666666,\n",
       " 0.16666666666666666,\n",
       " 0.16666666666666666,\n",
       " 0.16666666666666666,\n",
       " 0.16666666666666666,\n",
       " 0.16666666666666666,\n",
       " 0.16666666666666666,\n",
       " 0.16666666666666666,\n",
       " 0.16666666666666666,\n",
       " 0.125,\n",
       " 0.125,\n",
       " 0.125,\n",
       " 0.08333333333333333,\n",
       " 0.041666666666666664,\n",
       " 0.041666666666666664,\n",
       " 0.041666666666666664,\n",
       " 0.041666666666666664,\n",
       " 0.041666666666666664,\n",
       " 0.041666666666666664,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
