{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week8 Advanced\n",
    "- LLaMA 3.2 모델의 양자화에 따른 GPU 사용량 비교\n",
    "\n",
    "##  개요\n",
    "- 모델: **Bllossom/llama-3.2-Korean-Bllossom-3B** \n",
    "- 위 모델을 로드하여 비양자화, 8비트, 4비트로 로드\n",
    "- gpu 사용량 분석하여 메모리 절약 효과를 분석석  \n",
    "\n",
    "##  코드 실행 흐름\n",
    "1. **비양자화 모델 로드 및 추론 수행**\n",
    "   - `bfloat16` 모델을 로드하고 **GPU 사용량**을 측정\n",
    "   - 프롬프트를 입력받아 **추론 후 GPU 사용량**을 기록\n",
    "\n",
    "2. **8비트 양자화 모델 로드 및 추론 수행**\n",
    "   - `load_in_8bit=True` 옵션을 사용하여 8비트 양자화 모델 로드\n",
    "   - **모델 로드 시 GPU 사용량 감소 효과 확인**\n",
    "   - 동일한 프롬프트로 추론하고 **GPU 사용량 기록**\n",
    "\n",
    "3. **4비트 양자화 모델 로드 및 추론 수행**\n",
    "   - `load_in_4bit=True` 옵션을 사용하여 4비트 양자화 모델 로드\n",
    "   - **가장 적은 GPU 메모리를 사용하면서도 모델을 실행 가능**\n",
    "   - 동일한 프롬프트로 추론 후 **GPU 사용량 기록**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "양자화 전 모델 GPU 사용량: 6128.33MB (최대 6128.33MB)\n",
      "\n",
      "[양자화 전] 모델 출력: 서울의 관광코스를 짜고 싶습니다. 외국인이 왔을 때 역사적으로 많은 경험을 얻을 수 있도록 설계해주세요. 서울의 주요 관광지와 그들의 역사적 의미를 소개합니다.\n",
      "\n",
      "### 1. 경복궁\n",
      "경복궁은 조선 시대의 왕궁으로, 1395년 왕조 창건 후 1398년까지 13대 왕이 재위한 곳입니다. 경복궁은 조선 시대의 문화와 역사, 아름다움을 한곳으로, 왕궁의 전통적인 건축물과 정원, 궁궐의 내부를 경험할 수 있습니다.\n",
      "\n",
      "### 2. 성북대성전\n",
      "성북대성전은 조선 중기(15세기)에 세워진 사찰로, 조선 시대의 사찰 중에서 가장 큰 규모와 아름다움을 자랑합니다. 성북대성전은 조선의 역사와 문화를 이해할 수 있는 중요한 곳입니다.\n",
      "\n",
      "### 3. 경복궁 정원\n",
      "경복궁 정원은 조선 시대의 정원 건축 기술과 아름다움을 보여주는 곳입니다. 정원에는 다양한 식물과 인공수목이 자리 잡고 있으며, 정원 속에 있는 수영장, 정원 경로 등도 관람할 수 있습니다.\n",
      "\n",
      "### 4. 인사당\n",
      "인사당은 조선 중기(15세기)에 세워진 사찰로, 조선 시대의 사찰 중에서 가장 아름다운 건축물 중 하나입니다. 인사당은 정원 속에 위치해 있으며, 정원 속의 수영장과 수영장 주변의 신라 유적이 관람할 수 있습니다.\n",
      "\n",
      "### 5. 서울시립박물관\n",
      "서울시립박물관은 서울에서 가장 큰 박물관으로, 조선 시대부터 현대까지의 서울의 역사와 문화를 전시한 곳입니다. 박물관에는 다양한 전시물과 전시회가 열리고 있으며, 박물관 내에 있는 정원과 공원도 관람할 수 있습니다.\n",
      "\n",
      "### 6. 청계천\n",
      "청계천은 조선 시대의 주변 지역에 위치한 강으로, 서울의 역사와 문화를 이해할 수 있는 중요한 곳입니다. 청계천은 조선 시대의 상인들이 활동한 곳이었으며, 현재는 서울의 중심지로 자리 잡고 있습니다.\n",
      "\n",
      "### 7. 성북대성전 정원\n",
      "성북대성전 정원은 조선 중기(15세기)에 세워진 사찰로, 조선 시대의 정원 건축 기술과 아름다움을 보여주는 곳입니다. 정원에는 다양한 식물과 인공수목이 자리 잡고 있으며, 정원 속에 있는 수영장과 신라 유적도 관람할 수 있습니다.\n",
      "\n",
      "### 8. 인사당 정원\n",
      "인사당 정원은 조선 중기(15세기)에 세워진 사찰로, 조선 시대의 정원 건축 기술과 아름다움을 보여주는 곳입니다. 정원에는 다양한 식물과 인공수목이 자리 잡고 있으며, 정원 속에 있는 수영장과 신라 유적도 관람할 수 있습니다.\n",
      "\n",
      "### 9. 서울시립박물관 정원\n",
      "서울시립박물관 정원은 박물관 내에 위치한 정원으로, 박물관 전시물과 함께 관람할 수 있는 정원입니다. 정원에는 다양한 식물과 인공수목이 자리 잡고 있으며, 정원 속에 있는 수영장과 공원도 관람할 수 있습니다.\n",
      "\n",
      "### 10. 청계천 정원\n",
      "청계천 정원은 청계천 주변에 위치한 공원으로, 서울의 역사와 문화를 이해할 수 있는 중요한 곳입니다. 정원에는 다양한 식물과 인공수목이 자리 잡고 있으며, 정원 속에 있는 수영장과 신라 유적도 관람할 수 있습니다.\n",
      "\n",
      "### 11. 성북대성전 신라 유적\n",
      "성북대성전 신라 유적은 성북대성전 주변에 위치한 신라 유적으로, 7세기 신라 시대의 유적이 남아 있습니다. 유적은 신라 시대의 문화와 역사, 아름다움을 이해할 수 있는 중요한 곳입니다.\n",
      "\n",
      "### 12. 경복궁 궁궐\n",
      "경복궁 궁궐은 조선 시대의 왕궁으로, 1395년 왕조 창건 후 1398년까지 13대 왕이 재위한 곳입니다. 궁궐에는 왕궁의 전통적인 건축물과 정원, 궁궐의 내부가 관람할 수 있습니다.\n",
      "\n",
      "###\n",
      "\n",
      "[양자화 전] 추론 시 GPU 사용량: 6136.47MB (최대 6262.07MB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.14s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8비트 양자화 후 모델 GPU 사용량: 3451.41MB (최대 3475.37MB)\n",
      "\n",
      "[8비트 양자화] 모델 출력: 서울의 관광코스를 짜고 싶습니다. 외국인이 왔을 때 역사적으로 많은 경험을 얻을 수 있도록 설계해주세요. 서울의 대표적인 명소와 함께 다양한 문화를 경험할 수 있는 방법을 제안해 주세요.\n",
      "\n",
      "### 서울의 대표적인 명소와 문화 경험 방법\n",
      "\n",
      "1. **경복궁**\n",
      "   - ** 역사적 경험**: 한국의 역사와 문화를 이해할 수 있는 장소입니다. 경복궁은 조선 시대에 남아 있는 유일한 궁궐로, 건축물과 문물, 역사적인 장소들을 감상할 수 있습니다.\n",
      "   - **문화 경험**: 궁궐 내부에서 다양한 문화적 경험을 할 수 있습니다. 예를 들어, 궁궐 내에서 진행되는 전통 공연을 감상하거나, 전통 의상으로 상装을 입고 궁궐을 산책할 수 있습니다.\n",
      "\n",
      "2. **정성동의 전통시장**\n",
      "   - **문화 경험**: 전통시장에서 다양한 전통 음식과 소품을 맛보며, 전통 의상을 입고 전통 공연을 감상할 수 있습니다. 전통시장은 한국의 전통과 문화를 체험할 수 있는 좋은 장소입니다.\n",
      "   - **명소**: 정성동의 전통시장에서 다양한 전통 음식을 맛보며, 전통 의상을 입고 전통 공연을 감상할 수 있습니다.\n",
      "\n",
      "3. **한강**\n",
      "   - **명소**: 서울의 대표적인 명소 중 하나로, 한강을 따라 걷거나 보트를 타며 서울의 풍경을 감상할 수 있습니다.\n",
      "   - **문화 경험**: 한강에 위치한 전통 공원인 한강공원에서 전통 공연을 감상하거나, 한강을 따라 걷면서 서울의 문화를 체험할 수 있습니다.\n",
      "\n",
      "4. **남대문시장**\n",
      "   - **문화 경험**: 전통시장에서 다양한 전통 음식을 맛보며, 전통 의상을 입고 전통 공연을 감상할 수 있습니다.\n",
      "   - **명소**: 남대문시장은 서울의 대표적인 전통시장 중 하나로, 다양한 전통 음식을 맛보며 전통 문화를 체험할 수 있습니다.\n",
      "\n",
      "5. **동대문디자인플라자**\n",
      "   - **문화 경험**: 다양한 전통과 현대 문화를 체험할 수 있는 공간입니다. 전통 공연을 감상하거나, 전통 의상을 입고 전통 공연을 감상할 수 있습니다.\n",
      "   - **명소**: 동대문디자인플라자는 다양한 전통과 현대 문화를 체험할 수 있는 공간으로, 서울의 문화적 다양성을 체험할 수 있습니다.\n",
      "\n",
      "6. **한남동의 전통시장**\n",
      "   - **문화 경험**: 전통시장에서 다양한 전통 음식을 맛보며, 전통 의상을 입고 전통 공연을 감상할 수 있습니다.\n",
      "   - **명소**: 한남동의 전통시장은 서울의 대표적인 전통시장 중 하나로, 다양한 전통 음식을 맛보며 전통 문화를 체험할 수 있습니다.\n",
      "\n",
      "7. **영등포구의 전통시장**\n",
      "   - **문화 경험**: 전통시장에서 다양한 전통 음식을 맛보며, 전통 의상을 입고 전통 공연을 감상할 수 있습니다.\n",
      "   - **명소**: 영등포구의 전통시장은 서울의 대표적인 전통시장 중 하나로, 다양한 전통 음식을 맛보며 전통 문화를 체험할 수 있습니다.\n",
      "\n",
      "### 서울의 다양한 문화 체험 방법\n",
      "\n",
      "1. **전통 공연 감상**\n",
      "   - **명소**: 경복궁, 한강공원, 동대문디자인플라자 등에서 전통 공연을 감상할 수 있습니다.\n",
      "   - **문화 경험**: 전통 공연을 통해 한국의 전통 문화를 체험할 수 있습니다.\n",
      "\n",
      "2. **전통 의상 입고**\n",
      "   - **명소**: 경복궁, 정성동의 전통시장, 한남동의 전통시장 등에서 전통 의상을 입고 전통 공연을 감상할 수 있습니다.\n",
      "   - **문화 경험**: 전통 의상을 입고 전통 공연을 통해 한국의 전통 문화를 체험할 수 있습니다.\n",
      "\n",
      "3. **전통 음식 맛보는 전통시장**\n",
      "   - **명소**: 정성동의 전통시장, 남대문시장, 한남동의 전통시장 등에서 다양한 전통 음식을 맛보는 전통시장을 방문할 수 있습니다.\n",
      "   - **문화 경험**: 전통 음식을 맛보며 한국\n",
      "\n",
      "[8비트 양자화] 추론 시 GPU 사용량: 3453.21MB (최대 3579.78MB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.31s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4비트 양자화 후 모델 GPU 사용량: 2158.84MB (최대 2195.94MB)\n",
      "\n",
      "[4비트 양자화] 모델 출력: 서울의 관광코스를 짜고 싶습니다. 외국인이 왔을 때 역사적으로 많은 경험을 얻을 수 있도록 설계해주세요. 서울의 역사적 Sites를 순회하며, 서울의 문화와 역사적 상징을 깊이 이해해보세요. \n",
      "\n",
      "1.  **고려시대( 고려, 고려시대, 고려왕국)**\n",
      "\n",
      "    *   **고려의 역사적 sites** : 고려의 역사적 sites를 방문하여 고려시대의 역사와 문화를 깊이 이해해보세요.\n",
      "    *   **고려의 문화적 상징** : 고려의 문화적 상징, 예를 들어 고려의 전통 의상, 고려의 전통 음악, 고려의 전통 전시회를 방문하여 고려의 문화를 깊이 이해해보세요.\n",
      "\n",
      "2.  **중세시대(고려, 고려시대, 고려왕국)**\n",
      "\n",
      "    *   **고려의 역사적 sites** : 고려의 역사적 sites를 방문하여 중세시대의 역사와 문화를 깊이 이해해보세요.\n",
      "    *   **고려의 문화적 상징** : 고려의 문화적 상징, 예를 들어 고려의 전통 의상, 고려의 전통 음악, 고려의 전통 전시회를 방문하여 고려의 문화를 깊이 이해해보세요.\n",
      "\n",
      "3.  **현대시대(서울, 고려, 고려시대)**\n",
      "\n",
      "    *   **서울의 역사적 sites** : 서울의 역사적 sites를 방문하여 현대시대의 역사와 문화를 깊이 이해해보세요.\n",
      "    *   **서울의 문화적 상징** : 서울의 문화적 상징, 예를 들어 서울의 전통 의상, 서울의 전통 음악, 서울의 전통 전시회를 방문하여 서울의 문화를 깊이 이해해보세요.\n",
      "\n",
      "### 서울의 역사적 Sites\n",
      "\n",
      "1.  **고려시대(고려, 고려시대, 고려왕국)**\n",
      "\n",
      "    *   **고려의 역사적 sites** : 고려의 역사적 sites를 방문하여 고려시대의 역사와 문화를 깊이 이해해보세요. \n",
      "\n",
      "    *   **고려의 역사적 sites** : 고려의 역사적 sites를 방문하여 고려시대의 역사와 문화를 깊이 이해해보세요. \n",
      "\n",
      "2.  **중세시대(고려, 고려시대, 고려왕국)**\n",
      "\n",
      "    *   **고려의 역사적 sites** : 고려의 역사적 sites를 방문하여 중세시대의 역사와 문화를 깊이 이해해보세요. \n",
      "\n",
      "    *   **고려의 역사적 sites** : 고려의 역사적 sites를 방문하여 중세시대의 역사와 문화를 깊이 이해해보세요. \n",
      "\n",
      "3.  **현대시대(서울, 고려, 고려시대)**\n",
      "\n",
      "    *   **서울의 역사적 sites** : 서울의 역사적 sites를 방문하여 현대시대의 역사와 문화를 깊이 이해해보세요. \n",
      "\n",
      "    *   **서울의 역사적 sites** : 서울의 역사적 sites를 방문하여 현대시대의 역사와 문화를 깊이 이해해보세요. \n",
      "\n",
      "### 서울의 문화적 상징\n",
      "\n",
      "1.  **고려의 전통 의상** : 고려의 전통 의상, 예를 들어 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의상, 고려의 전통 의\n",
      "\n",
      "[4비트 양자화] 추론 시 GPU 사용량: 2158.84MB (최대 2284.44MB)\n",
      "\n",
      "📊 최종 비교 결과:\n",
      "🔹 모델 로드 후 GPU 절약량 (8비트): 2676.92MB (최대 2652.97MB)\n",
      "🔹 모델 로드 후 GPU 절약량 (4비트): 3969.50MB (최대 3932.40MB)\n",
      "🔹 모델 추론 시 GPU 절약량 (8비트): 2683.25MB (최대 2682.29MB)\n",
      "🔹 모델 추론 시 GPU 절약량 (4비트): 3977.62MB (최대 3977.63MB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "def get_gpu_memory():\n",
    "    \"\"\"GPU 메모리 사용량 반환 (MB 단위)\"\"\"\n",
    "    torch.cuda.synchronize()\n",
    "    mem_used = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "    peak_mem_used = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
    "    return mem_used, peak_mem_used\n",
    "\n",
    "def run_inference(model, tokenizer, prompt):\n",
    "    \"\"\"모델 추론 및 GPU 메모리 사용량 측정\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_length=1024)\n",
    "\n",
    "    mem_used, peak_mem_used = get_gpu_memory()\n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return output_text, mem_used, peak_mem_used\n",
    "\n",
    "model_id = 'Bllossom/llama-3.2-Korean-Bllossom-3B'\n",
    "tokenizer_base = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "model_base = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "mem_base, peak_mem_base = get_gpu_memory()\n",
    "print(f\"양자화 전 모델 GPU 사용량: {mem_base:.2f}MB (최대 {peak_mem_base:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "prompt = \"서울의 관광코스를 짜고 싶습니다. 외국인이 왔을 때 역사적으로 많은 경험을 얻을 수 있도록 설계해주세요\"\n",
    "output_base, inf_mem_base, peak_inf_mem_base = run_inference(model_base, tokenizer_base, prompt)\n",
    "print(f\"[양자화 전] 모델 출력: {output_base}\", end=\"\\n\\n\")\n",
    "print(f\"[양자화 전] 추론 시 GPU 사용량: {inf_mem_base:.2f}MB (최대 {peak_inf_mem_base:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "del model_base\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "tokenizer_8bit = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "model_8bit = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "mem_8bit, peak_mem_8bit = get_gpu_memory()\n",
    "print(f\"8비트 양자화 후 모델 GPU 사용량: {mem_8bit:.2f}MB (최대 {peak_mem_8bit:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "output_8bit, inf_mem_8bit, peak_inf_mem_8bit = run_inference(model_8bit, tokenizer_8bit, prompt)\n",
    "print(f\"[8비트 양자화] 모델 출력: {output_8bit}\", end=\"\\n\\n\")\n",
    "print(f\"[8비트 양자화] 추론 시 GPU 사용량: {inf_mem_8bit:.2f}MB (최대 {peak_inf_mem_8bit:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "del model_8bit\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "quantization_config_4bit = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "tokenizer_4bit = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "model_4bit = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config_4bit,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "\n",
    "mem_4bit, peak_mem_4bit = get_gpu_memory()\n",
    "print(f\"4비트 양자화 후 모델 GPU 사용량: {mem_4bit:.2f}MB (최대 {peak_mem_4bit:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "output_4bit, inf_mem_4bit, peak_inf_mem_4bit = run_inference(model_4bit, tokenizer_4bit, prompt)\n",
    "print(f\"[4비트 양자화] 모델 출력: {output_4bit}\", end=\"\\n\\n\")\n",
    "print(f\"[4비트 양자화] 추론 시 GPU 사용량: {inf_mem_4bit:.2f}MB (최대 {peak_inf_mem_4bit:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "del model_4bit\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "print(\"📊 최종 비교 결과:\")\n",
    "print(f\"🔹 모델 로드 후 GPU 절약량 (8비트): {mem_base - mem_8bit:.2f}MB (최대 {peak_mem_base - peak_mem_8bit:.2f}MB)\")\n",
    "print(f\"🔹 모델 로드 후 GPU 절약량 (4비트): {mem_base - mem_4bit:.2f}MB (최대 {peak_mem_base - peak_mem_4bit:.2f}MB)\")\n",
    "print(f\"🔹 모델 추론 시 GPU 절약량 (8비트): {inf_mem_base - inf_mem_8bit:.2f}MB (최대 {peak_inf_mem_base - peak_inf_mem_8bit:.2f}MB)\")\n",
    "print(f\"🔹 모델 추론 시 GPU 절약량 (4비트): {inf_mem_base - inf_mem_4bit:.2f}MB (최대 {peak_inf_mem_base - peak_inf_mem_4bit:.2f}MB)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론\n",
    "- 4비트 양자화가 가장 큰 GPU 메모리 절약 효과를 보임\n",
    "- 8비트 양자화도 효과적이지만, 4비트보다는 메모리를 더 많이 사용\n",
    "- 양자화를 할 수록 답변의 퀄리티가 떨어지다가, 4비트에서부터는 대답이 망가진 것을 확인\n",
    "- 이후 챗봇에 엮어서 진행할 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>양자화 방식</th>\n",
       "      <th>모델 로드 GPU 사용량 (MB)</th>\n",
       "      <th>모델 로드 최대 GPU 사용량 (MB)</th>\n",
       "      <th>추론 GPU 사용량 (MB)</th>\n",
       "      <th>추론 최대 GPU 사용량 (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>비양자화</td>\n",
       "      <td>6128.334473</td>\n",
       "      <td>6128.334473</td>\n",
       "      <td>6136.468262</td>\n",
       "      <td>6262.069336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8비트 양자화</td>\n",
       "      <td>3451.412598</td>\n",
       "      <td>3475.369141</td>\n",
       "      <td>3453.213379</td>\n",
       "      <td>3579.779297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4비트 양자화</td>\n",
       "      <td>2158.835449</td>\n",
       "      <td>2195.937500</td>\n",
       "      <td>2158.844238</td>\n",
       "      <td>2284.437500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    양자화 방식  모델 로드 GPU 사용량 (MB)  모델 로드 최대 GPU 사용량 (MB)  추론 GPU 사용량 (MB)  \\\n",
       "0     비양자화         6128.334473            6128.334473      6136.468262   \n",
       "1  8비트 양자화         3451.412598            3475.369141      3453.213379   \n",
       "2  4비트 양자화         2158.835449            2195.937500      2158.844238   \n",
       "\n",
       "   추론 최대 GPU 사용량 (MB)  \n",
       "0         6262.069336  \n",
       "1         3579.779297  \n",
       "2         2284.437500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 정리\n",
    "data = {\n",
    "    \"양자화 방식\": [\"비양자화\", \"8비트 양자화\", \"4비트 양자화\"],\n",
    "    \"모델 로드 GPU 사용량 (MB)\": [mem_base, mem_8bit, mem_4bit],\n",
    "    \"모델 로드 최대 GPU 사용량 (MB)\": [peak_mem_base, peak_mem_8bit, peak_mem_4bit],\n",
    "    \"추론 GPU 사용량 (MB)\": [inf_mem_base, inf_mem_8bit, inf_mem_4bit],\n",
    "    \"추론 최대 GPU 사용량 (MB)\": [peak_inf_mem_base, peak_inf_mem_8bit, peak_inf_mem_4bit],\n",
    "}\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "챗봇에서 아래와 같은 형태로 4비트 양자화를 하여 모델을 구현했습니다.\n",
    "\n",
    "```python\n",
    "model_id = 'Bllossom/llama-3.2-Korean-Bllossom-3B'\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "custom_pipeline = KoreanLlamaPipeline(model, tokenizer)\n",
    "llm = KoreanLlamaLangChainLLM(pipeline=custom_pipeline)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
