{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week8 Advanced\n",
    "- LLaMA 3.2 λ¨λΈμ μ–‘μν™”μ— λ”°λ¥Έ GPU μ‚¬μ©λ‰ λΉ„κµ\n",
    "\n",
    "##  κ°μ”\n",
    "- λ¨λΈ: **Bllossom/llama-3.2-Korean-Bllossom-3B** \n",
    "- μ„ λ¨λΈμ„ λ΅λ“ν•μ—¬ λΉ„μ–‘μν™”, 8λΉ„νΈ, 4λΉ„νΈλ΅ λ΅λ“\n",
    "- gpu μ‚¬μ©λ‰ λ¶„μ„ν•μ—¬ λ©”λ¨λ¦¬ μ μ•½ ν¨κ³Όλ¥Ό λ¶„μ„μ„  \n",
    "\n",
    "##  μ½”λ“ μ‹¤ν–‰ νλ¦„\n",
    "1. **λΉ„μ–‘μν™” λ¨λΈ λ΅λ“ λ° μ¶”λ΅  μν–‰**\n",
    "   - `bfloat16` λ¨λΈμ„ λ΅λ“ν•κ³  **GPU μ‚¬μ©λ‰**μ„ μΈ΅μ •\n",
    "   - ν”„λ΅¬ν”„νΈλ¥Ό μ…λ ¥λ°›μ•„ **μ¶”λ΅  ν›„ GPU μ‚¬μ©λ‰**μ„ κΈ°λ΅\n",
    "\n",
    "2. **8λΉ„νΈ μ–‘μν™” λ¨λΈ λ΅λ“ λ° μ¶”λ΅  μν–‰**\n",
    "   - `load_in_8bit=True` μµμ…μ„ μ‚¬μ©ν•μ—¬ 8λΉ„νΈ μ–‘μν™” λ¨λΈ λ΅λ“\n",
    "   - **λ¨λΈ λ΅λ“ μ‹ GPU μ‚¬μ©λ‰ κ°μ† ν¨κ³Ό ν™•μΈ**\n",
    "   - λ™μΌν• ν”„λ΅¬ν”„νΈλ΅ μ¶”λ΅ ν•κ³  **GPU μ‚¬μ©λ‰ κΈ°λ΅**\n",
    "\n",
    "3. **4λΉ„νΈ μ–‘μν™” λ¨λΈ λ΅λ“ λ° μ¶”λ΅  μν–‰**\n",
    "   - `load_in_4bit=True` μµμ…μ„ μ‚¬μ©ν•μ—¬ 4λΉ„νΈ μ–‘μν™” λ¨λΈ λ΅λ“\n",
    "   - **κ°€μ¥ μ μ€ GPU λ©”λ¨λ¦¬λ¥Ό μ‚¬μ©ν•λ©΄μ„λ„ λ¨λΈμ„ μ‹¤ν–‰ κ°€λ¥**\n",
    "   - λ™μΌν• ν”„λ΅¬ν”„νΈλ΅ μ¶”λ΅  ν›„ **GPU μ‚¬μ©λ‰ κΈ°λ΅**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|β–β–β–β–β–β–β–β–β–β–| 2/2 [00:02<00:00,  1.05s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μ–‘μν™” μ „ λ¨λΈ GPU μ‚¬μ©λ‰: 6128.33MB (μµλ€ 6128.33MB)\n",
      "\n",
      "[μ–‘μν™” μ „] λ¨λΈ μ¶λ ¥: μ„μΈμ κ΄€κ΄‘μ½”μ¤λ¥Ό μ§κ³  μ‹¶μµλ‹λ‹¤. μ™Έκµ­μΈμ΄ μ™”μ„ λ• μ—­μ‚¬μ μΌλ΅ λ§μ€ κ²½ν—μ„ μ–»μ„ μ μλ„λ΅ μ„¤κ³„ν•΄μ£Όμ„Έμ”. μ„μΈμ μ£Όμ” κ΄€κ΄‘μ§€μ™€ κ·Έλ“¤μ μ—­μ‚¬μ  μλ―Έλ¥Ό μ†κ°ν•©λ‹λ‹¤.\n",
      "\n",
      "### 1. κ²½λ³µκ¶\n",
      "κ²½λ³µκ¶μ€ μ΅°μ„  μ‹λ€μ μ™•κ¶μΌλ΅, 1395λ…„ μ™•μ΅° μ°½κ±΄ ν›„ 1398λ…„κΉμ§€ 13λ€ μ™•μ΄ μ¬μ„ν• κ³³μ…λ‹λ‹¤. κ²½λ³µκ¶μ€ μ΅°μ„  μ‹λ€μ λ¬Έν™”μ™€ μ—­μ‚¬, μ•„λ¦„λ‹¤μ›€μ„ ν•κ³³μΌλ΅, μ™•κ¶μ μ „ν†µμ μΈ κ±΄μ¶•λ¬Όκ³Ό μ •μ›, κ¶κ¶μ λ‚΄λ¶€λ¥Ό κ²½ν—ν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "### 2. μ„±λ¶λ€μ„±μ „\n",
      "μ„±λ¶λ€μ„±μ „μ€ μ΅°μ„  μ¤‘κΈ°(15μ„ΈκΈ°)μ— μ„Έμ›μ§„ μ‚¬μ°°λ΅, μ΅°μ„  μ‹λ€μ μ‚¬μ°° μ¤‘μ—μ„ κ°€μ¥ ν° κ·λ¨μ™€ μ•„λ¦„λ‹¤μ›€μ„ μλ‘ν•©λ‹λ‹¤. μ„±λ¶λ€μ„±μ „μ€ μ΅°μ„ μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό μ΄ν•΄ν•  μ μλ” μ¤‘μ”ν• κ³³μ…λ‹λ‹¤.\n",
      "\n",
      "### 3. κ²½λ³µκ¶ μ •μ›\n",
      "κ²½λ³µκ¶ μ •μ›μ€ μ΅°μ„  μ‹λ€μ μ •μ› κ±΄μ¶• κΈ°μ κ³Ό μ•„λ¦„λ‹¤μ›€μ„ λ³΄μ—¬μ£Όλ” κ³³μ…λ‹λ‹¤. μ •μ›μ—λ” λ‹¤μ–‘ν• μ‹λ¬Όκ³Ό μΈκ³µμλ©μ΄ μλ¦¬ μ΅κ³  μμΌλ©°, μ •μ› μ†μ— μλ” μμμ¥, μ •μ› κ²½λ΅ λ“±λ„ κ΄€λν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "### 4. μΈμ‚¬λ‹Ή\n",
      "μΈμ‚¬λ‹Ήμ€ μ΅°μ„  μ¤‘κΈ°(15μ„ΈκΈ°)μ— μ„Έμ›μ§„ μ‚¬μ°°λ΅, μ΅°μ„  μ‹λ€μ μ‚¬μ°° μ¤‘μ—μ„ κ°€μ¥ μ•„λ¦„λ‹¤μ΄ κ±΄μ¶•λ¬Ό μ¤‘ ν•λ‚μ…λ‹λ‹¤. μΈμ‚¬λ‹Ήμ€ μ •μ› μ†μ— μ„μΉν•΄ μμΌλ©°, μ •μ› μ†μ μμμ¥κ³Ό μμμ¥ μ£Όλ³€μ μ‹ λΌ μ μ μ΄ κ΄€λν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "### 5. μ„μΈμ‹λ¦½λ°•λ¬Όκ΄€\n",
      "μ„μΈμ‹λ¦½λ°•λ¬Όκ΄€μ€ μ„μΈμ—μ„ κ°€μ¥ ν° λ°•λ¬Όκ΄€μΌλ΅, μ΅°μ„  μ‹λ€λ¶€ν„° ν„λ€κΉμ§€μ μ„μΈμ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό μ „μ‹ν• κ³³μ…λ‹λ‹¤. λ°•λ¬Όκ΄€μ—λ” λ‹¤μ–‘ν• μ „μ‹λ¬Όκ³Ό μ „μ‹νκ°€ μ—΄λ¦¬κ³  μμΌλ©°, λ°•λ¬Όκ΄€ λ‚΄μ— μλ” μ •μ›κ³Ό κ³µμ›λ„ κ΄€λν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "### 6. μ²­κ³„μ²\n",
      "μ²­κ³„μ²μ€ μ΅°μ„  μ‹λ€μ μ£Όλ³€ μ§€μ—­μ— μ„μΉν• κ°•μΌλ΅, μ„μΈμ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό μ΄ν•΄ν•  μ μλ” μ¤‘μ”ν• κ³³μ…λ‹λ‹¤. μ²­κ³„μ²μ€ μ΅°μ„  μ‹λ€μ μƒμΈλ“¤μ΄ ν™λ™ν• κ³³μ΄μ—μΌλ©°, ν„μ¬λ” μ„μΈμ μ¤‘μ‹¬μ§€λ΅ μλ¦¬ μ΅κ³  μμµλ‹λ‹¤.\n",
      "\n",
      "### 7. μ„±λ¶λ€μ„±μ „ μ •μ›\n",
      "μ„±λ¶λ€μ„±μ „ μ •μ›μ€ μ΅°μ„  μ¤‘κΈ°(15μ„ΈκΈ°)μ— μ„Έμ›μ§„ μ‚¬μ°°λ΅, μ΅°μ„  μ‹λ€μ μ •μ› κ±΄μ¶• κΈ°μ κ³Ό μ•„λ¦„λ‹¤μ›€μ„ λ³΄μ—¬μ£Όλ” κ³³μ…λ‹λ‹¤. μ •μ›μ—λ” λ‹¤μ–‘ν• μ‹λ¬Όκ³Ό μΈκ³µμλ©μ΄ μλ¦¬ μ΅κ³  μμΌλ©°, μ •μ› μ†μ— μλ” μμμ¥κ³Ό μ‹ λΌ μ μ λ„ κ΄€λν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "### 8. μΈμ‚¬λ‹Ή μ •μ›\n",
      "μΈμ‚¬λ‹Ή μ •μ›μ€ μ΅°μ„  μ¤‘κΈ°(15μ„ΈκΈ°)μ— μ„Έμ›μ§„ μ‚¬μ°°λ΅, μ΅°μ„  μ‹λ€μ μ •μ› κ±΄μ¶• κΈ°μ κ³Ό μ•„λ¦„λ‹¤μ›€μ„ λ³΄μ—¬μ£Όλ” κ³³μ…λ‹λ‹¤. μ •μ›μ—λ” λ‹¤μ–‘ν• μ‹λ¬Όκ³Ό μΈκ³µμλ©μ΄ μλ¦¬ μ΅κ³  μμΌλ©°, μ •μ› μ†μ— μλ” μμμ¥κ³Ό μ‹ λΌ μ μ λ„ κ΄€λν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "### 9. μ„μΈμ‹λ¦½λ°•λ¬Όκ΄€ μ •μ›\n",
      "μ„μΈμ‹λ¦½λ°•λ¬Όκ΄€ μ •μ›μ€ λ°•λ¬Όκ΄€ λ‚΄μ— μ„μΉν• μ •μ›μΌλ΅, λ°•λ¬Όκ΄€ μ „μ‹λ¬Όκ³Ό ν•¨κ» κ΄€λν•  μ μλ” μ •μ›μ…λ‹λ‹¤. μ •μ›μ—λ” λ‹¤μ–‘ν• μ‹λ¬Όκ³Ό μΈκ³µμλ©μ΄ μλ¦¬ μ΅κ³  μμΌλ©°, μ •μ› μ†μ— μλ” μμμ¥κ³Ό κ³µμ›λ„ κ΄€λν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "### 10. μ²­κ³„μ² μ •μ›\n",
      "μ²­κ³„μ² μ •μ›μ€ μ²­κ³„μ² μ£Όλ³€μ— μ„μΉν• κ³µμ›μΌλ΅, μ„μΈμ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό μ΄ν•΄ν•  μ μλ” μ¤‘μ”ν• κ³³μ…λ‹λ‹¤. μ •μ›μ—λ” λ‹¤μ–‘ν• μ‹λ¬Όκ³Ό μΈκ³µμλ©μ΄ μλ¦¬ μ΅κ³  μμΌλ©°, μ •μ› μ†μ— μλ” μμμ¥κ³Ό μ‹ λΌ μ μ λ„ κ΄€λν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "### 11. μ„±λ¶λ€μ„±μ „ μ‹ λΌ μ μ \n",
      "μ„±λ¶λ€μ„±μ „ μ‹ λΌ μ μ μ€ μ„±λ¶λ€μ„±μ „ μ£Όλ³€μ— μ„μΉν• μ‹ λΌ μ μ μΌλ΅, 7μ„ΈκΈ° μ‹ λΌ μ‹λ€μ μ μ μ΄ λ‚¨μ•„ μμµλ‹λ‹¤. μ μ μ€ μ‹ λΌ μ‹λ€μ λ¬Έν™”μ™€ μ—­μ‚¬, μ•„λ¦„λ‹¤μ›€μ„ μ΄ν•΄ν•  μ μλ” μ¤‘μ”ν• κ³³μ…λ‹λ‹¤.\n",
      "\n",
      "### 12. κ²½λ³µκ¶ κ¶κ¶\n",
      "κ²½λ³µκ¶ κ¶κ¶μ€ μ΅°μ„  μ‹λ€μ μ™•κ¶μΌλ΅, 1395λ…„ μ™•μ΅° μ°½κ±΄ ν›„ 1398λ…„κΉμ§€ 13λ€ μ™•μ΄ μ¬μ„ν• κ³³μ…λ‹λ‹¤. κ¶κ¶μ—λ” μ™•κ¶μ μ „ν†µμ μΈ κ±΄μ¶•λ¬Όκ³Ό μ •μ›, κ¶κ¶μ λ‚΄λ¶€κ°€ κ΄€λν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "###\n",
      "\n",
      "[μ–‘μν™” μ „] μ¶”λ΅  μ‹ GPU μ‚¬μ©λ‰: 6136.47MB (μµλ€ 6262.07MB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|β–β–β–β–β–β–β–β–β–β–| 2/2 [00:06<00:00,  3.14s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8λΉ„νΈ μ–‘μν™” ν›„ λ¨λΈ GPU μ‚¬μ©λ‰: 3451.41MB (μµλ€ 3475.37MB)\n",
      "\n",
      "[8λΉ„νΈ μ–‘μν™”] λ¨λΈ μ¶λ ¥: μ„μΈμ κ΄€κ΄‘μ½”μ¤λ¥Ό μ§κ³  μ‹¶μµλ‹λ‹¤. μ™Έκµ­μΈμ΄ μ™”μ„ λ• μ—­μ‚¬μ μΌλ΅ λ§μ€ κ²½ν—μ„ μ–»μ„ μ μλ„λ΅ μ„¤κ³„ν•΄μ£Όμ„Έμ”. μ„μΈμ λ€ν‘μ μΈ λ…μ†μ™€ ν•¨κ» λ‹¤μ–‘ν• λ¬Έν™”λ¥Ό κ²½ν—ν•  μ μλ” λ°©λ²•μ„ μ μ•ν•΄ μ£Όμ„Έμ”.\n",
      "\n",
      "### μ„μΈμ λ€ν‘μ μΈ λ…μ†μ™€ λ¬Έν™” κ²½ν— λ°©λ²•\n",
      "\n",
      "1. **κ²½λ³µκ¶**\n",
      "   - ** μ—­μ‚¬μ  κ²½ν—**: ν•κµ­μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό μ΄ν•΄ν•  μ μλ” μ¥μ†μ…λ‹λ‹¤. κ²½λ³µκ¶μ€ μ΅°μ„  μ‹λ€μ— λ‚¨μ•„ μλ” μ μΌν• κ¶κ¶λ΅, κ±΄μ¶•λ¬Όκ³Ό λ¬Έλ¬Ό, μ—­μ‚¬μ μΈ μ¥μ†λ“¤μ„ κ°μƒν•  μ μμµλ‹λ‹¤.\n",
      "   - **λ¬Έν™” κ²½ν—**: κ¶κ¶ λ‚΄λ¶€μ—μ„ λ‹¤μ–‘ν• λ¬Έν™”μ  κ²½ν—μ„ ν•  μ μμµλ‹λ‹¤. μλ¥Ό λ“¤μ–΄, κ¶κ¶ λ‚΄μ—μ„ μ§„ν–‰λλ” μ „ν†µ κ³µμ—°μ„ κ°μƒν•κ±°λ‚, μ „ν†µ μμƒμΌλ΅ μƒθ£…μ„ μ…κ³  κ¶κ¶μ„ μ‚°μ±…ν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "2. **μ •μ„±λ™μ μ „ν†µμ‹μ¥**\n",
      "   - **λ¬Έν™” κ²½ν—**: μ „ν†µμ‹μ¥μ—μ„ λ‹¤μ–‘ν• μ „ν†µ μμ‹κ³Ό μ†ν’μ„ λ§›λ³΄λ©°, μ „ν†µ μμƒμ„ μ…κ³  μ „ν†µ κ³µμ—°μ„ κ°μƒν•  μ μμµλ‹λ‹¤. μ „ν†µμ‹μ¥μ€ ν•κµ­μ μ „ν†µκ³Ό λ¬Έν™”λ¥Ό μ²΄ν—ν•  μ μλ” μΆ‹μ€ μ¥μ†μ…λ‹λ‹¤.\n",
      "   - **λ…μ†**: μ •μ„±λ™μ μ „ν†µμ‹μ¥μ—μ„ λ‹¤μ–‘ν• μ „ν†µ μμ‹μ„ λ§›λ³΄λ©°, μ „ν†µ μμƒμ„ μ…κ³  μ „ν†µ κ³µμ—°μ„ κ°μƒν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "3. **ν•κ°•**\n",
      "   - **λ…μ†**: μ„μΈμ λ€ν‘μ μΈ λ…μ† μ¤‘ ν•λ‚λ΅, ν•κ°•μ„ λ”°λΌ κ±·κ±°λ‚ λ³΄νΈλ¥Ό νƒ€λ©° μ„μΈμ ν’κ²½μ„ κ°μƒν•  μ μμµλ‹λ‹¤.\n",
      "   - **λ¬Έν™” κ²½ν—**: ν•κ°•μ— μ„μΉν• μ „ν†µ κ³µμ›μΈ ν•κ°•κ³µμ›μ—μ„ μ „ν†µ κ³µμ—°μ„ κ°μƒν•κ±°λ‚, ν•κ°•μ„ λ”°λΌ κ±·λ©΄μ„ μ„μΈμ λ¬Έν™”λ¥Ό μ²΄ν—ν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "4. **λ‚¨λ€λ¬Έμ‹μ¥**\n",
      "   - **λ¬Έν™” κ²½ν—**: μ „ν†µμ‹μ¥μ—μ„ λ‹¤μ–‘ν• μ „ν†µ μμ‹μ„ λ§›λ³΄λ©°, μ „ν†µ μμƒμ„ μ…κ³  μ „ν†µ κ³µμ—°μ„ κ°μƒν•  μ μμµλ‹λ‹¤.\n",
      "   - **λ…μ†**: λ‚¨λ€λ¬Έμ‹μ¥μ€ μ„μΈμ λ€ν‘μ μΈ μ „ν†µμ‹μ¥ μ¤‘ ν•λ‚λ΅, λ‹¤μ–‘ν• μ „ν†µ μμ‹μ„ λ§›λ³΄λ©° μ „ν†µ λ¬Έν™”λ¥Ό μ²΄ν—ν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "5. **λ™λ€λ¬Έλ””μμΈν”λΌμ**\n",
      "   - **λ¬Έν™” κ²½ν—**: λ‹¤μ–‘ν• μ „ν†µκ³Ό ν„λ€ λ¬Έν™”λ¥Ό μ²΄ν—ν•  μ μλ” κ³µκ°„μ…λ‹λ‹¤. μ „ν†µ κ³µμ—°μ„ κ°μƒν•κ±°λ‚, μ „ν†µ μμƒμ„ μ…κ³  μ „ν†µ κ³µμ—°μ„ κ°μƒν•  μ μμµλ‹λ‹¤.\n",
      "   - **λ…μ†**: λ™λ€λ¬Έλ””μμΈν”λΌμλ” λ‹¤μ–‘ν• μ „ν†µκ³Ό ν„λ€ λ¬Έν™”λ¥Ό μ²΄ν—ν•  μ μλ” κ³µκ°„μΌλ΅, μ„μΈμ λ¬Έν™”μ  λ‹¤μ–‘μ„±μ„ μ²΄ν—ν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "6. **ν•λ‚¨λ™μ μ „ν†µμ‹μ¥**\n",
      "   - **λ¬Έν™” κ²½ν—**: μ „ν†µμ‹μ¥μ—μ„ λ‹¤μ–‘ν• μ „ν†µ μμ‹μ„ λ§›λ³΄λ©°, μ „ν†µ μμƒμ„ μ…κ³  μ „ν†µ κ³µμ—°μ„ κ°μƒν•  μ μμµλ‹λ‹¤.\n",
      "   - **λ…μ†**: ν•λ‚¨λ™μ μ „ν†µμ‹μ¥μ€ μ„μΈμ λ€ν‘μ μΈ μ „ν†µμ‹μ¥ μ¤‘ ν•λ‚λ΅, λ‹¤μ–‘ν• μ „ν†µ μμ‹μ„ λ§›λ³΄λ©° μ „ν†µ λ¬Έν™”λ¥Ό μ²΄ν—ν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "7. **μλ“±ν¬κµ¬μ μ „ν†µμ‹μ¥**\n",
      "   - **λ¬Έν™” κ²½ν—**: μ „ν†µμ‹μ¥μ—μ„ λ‹¤μ–‘ν• μ „ν†µ μμ‹μ„ λ§›λ³΄λ©°, μ „ν†µ μμƒμ„ μ…κ³  μ „ν†µ κ³µμ—°μ„ κ°μƒν•  μ μμµλ‹λ‹¤.\n",
      "   - **λ…μ†**: μλ“±ν¬κµ¬μ μ „ν†µμ‹μ¥μ€ μ„μΈμ λ€ν‘μ μΈ μ „ν†µμ‹μ¥ μ¤‘ ν•λ‚λ΅, λ‹¤μ–‘ν• μ „ν†µ μμ‹μ„ λ§›λ³΄λ©° μ „ν†µ λ¬Έν™”λ¥Ό μ²΄ν—ν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "### μ„μΈμ λ‹¤μ–‘ν• λ¬Έν™” μ²΄ν— λ°©λ²•\n",
      "\n",
      "1. **μ „ν†µ κ³µμ—° κ°μƒ**\n",
      "   - **λ…μ†**: κ²½λ³µκ¶, ν•κ°•κ³µμ›, λ™λ€λ¬Έλ””μμΈν”λΌμ λ“±μ—μ„ μ „ν†µ κ³µμ—°μ„ κ°μƒν•  μ μμµλ‹λ‹¤.\n",
      "   - **λ¬Έν™” κ²½ν—**: μ „ν†µ κ³µμ—°μ„ ν†µν•΄ ν•κµ­μ μ „ν†µ λ¬Έν™”λ¥Ό μ²΄ν—ν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "2. **μ „ν†µ μμƒ μ…κ³ **\n",
      "   - **λ…μ†**: κ²½λ³µκ¶, μ •μ„±λ™μ μ „ν†µμ‹μ¥, ν•λ‚¨λ™μ μ „ν†µμ‹μ¥ λ“±μ—μ„ μ „ν†µ μμƒμ„ μ…κ³  μ „ν†µ κ³µμ—°μ„ κ°μƒν•  μ μμµλ‹λ‹¤.\n",
      "   - **λ¬Έν™” κ²½ν—**: μ „ν†µ μμƒμ„ μ…κ³  μ „ν†µ κ³µμ—°μ„ ν†µν•΄ ν•κµ­μ μ „ν†µ λ¬Έν™”λ¥Ό μ²΄ν—ν•  μ μμµλ‹λ‹¤.\n",
      "\n",
      "3. **μ „ν†µ μμ‹ λ§›λ³΄λ” μ „ν†µμ‹μ¥**\n",
      "   - **λ…μ†**: μ •μ„±λ™μ μ „ν†µμ‹μ¥, λ‚¨λ€λ¬Έμ‹μ¥, ν•λ‚¨λ™μ μ „ν†µμ‹μ¥ λ“±μ—μ„ λ‹¤μ–‘ν• μ „ν†µ μμ‹μ„ λ§›λ³΄λ” μ „ν†µμ‹μ¥μ„ λ°©λ¬Έν•  μ μμµλ‹λ‹¤.\n",
      "   - **λ¬Έν™” κ²½ν—**: μ „ν†µ μμ‹μ„ λ§›λ³΄λ©° ν•κµ­\n",
      "\n",
      "[8λΉ„νΈ μ–‘μν™”] μ¶”λ΅  μ‹ GPU μ‚¬μ©λ‰: 3453.21MB (μµλ€ 3579.78MB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|β–β–β–β–β–β–β–β–β–β–| 2/2 [00:06<00:00,  3.31s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4λΉ„νΈ μ–‘μν™” ν›„ λ¨λΈ GPU μ‚¬μ©λ‰: 2158.84MB (μµλ€ 2195.94MB)\n",
      "\n",
      "[4λΉ„νΈ μ–‘μν™”] λ¨λΈ μ¶λ ¥: μ„μΈμ κ΄€κ΄‘μ½”μ¤λ¥Ό μ§κ³  μ‹¶μµλ‹λ‹¤. μ™Έκµ­μΈμ΄ μ™”μ„ λ• μ—­μ‚¬μ μΌλ΅ λ§μ€ κ²½ν—μ„ μ–»μ„ μ μλ„λ΅ μ„¤κ³„ν•΄μ£Όμ„Έμ”. μ„μΈμ μ—­μ‚¬μ  Sitesλ¥Ό μνν•λ©°, μ„μΈμ λ¬Έν™”μ™€ μ—­μ‚¬μ  μƒμ§•μ„ κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”. \n",
      "\n",
      "1.  **κ³ λ ¤μ‹λ€( κ³ λ ¤, κ³ λ ¤μ‹λ€, κ³ λ ¤μ™•κµ­)**\n",
      "\n",
      "    *   **κ³ λ ¤μ μ—­μ‚¬μ  sites** : κ³ λ ¤μ μ—­μ‚¬μ  sitesλ¥Ό λ°©λ¬Έν•μ—¬ κ³ λ ¤μ‹λ€μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”.\n",
      "    *   **κ³ λ ¤μ λ¬Έν™”μ  μƒμ§•** : κ³ λ ¤μ λ¬Έν™”μ  μƒμ§•, μλ¥Ό λ“¤μ–΄ κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμ•…, κ³ λ ¤μ μ „ν†µ μ „μ‹νλ¥Ό λ°©λ¬Έν•μ—¬ κ³ λ ¤μ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”.\n",
      "\n",
      "2.  **μ¤‘μ„Έμ‹λ€(κ³ λ ¤, κ³ λ ¤μ‹λ€, κ³ λ ¤μ™•κµ­)**\n",
      "\n",
      "    *   **κ³ λ ¤μ μ—­μ‚¬μ  sites** : κ³ λ ¤μ μ—­μ‚¬μ  sitesλ¥Ό λ°©λ¬Έν•μ—¬ μ¤‘μ„Έμ‹λ€μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”.\n",
      "    *   **κ³ λ ¤μ λ¬Έν™”μ  μƒμ§•** : κ³ λ ¤μ λ¬Έν™”μ  μƒμ§•, μλ¥Ό λ“¤μ–΄ κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμ•…, κ³ λ ¤μ μ „ν†µ μ „μ‹νλ¥Ό λ°©λ¬Έν•μ—¬ κ³ λ ¤μ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”.\n",
      "\n",
      "3.  **ν„λ€μ‹λ€(μ„μΈ, κ³ λ ¤, κ³ λ ¤μ‹λ€)**\n",
      "\n",
      "    *   **μ„μΈμ μ—­μ‚¬μ  sites** : μ„μΈμ μ—­μ‚¬μ  sitesλ¥Ό λ°©λ¬Έν•μ—¬ ν„λ€μ‹λ€μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”.\n",
      "    *   **μ„μΈμ λ¬Έν™”μ  μƒμ§•** : μ„μΈμ λ¬Έν™”μ  μƒμ§•, μλ¥Ό λ“¤μ–΄ μ„μΈμ μ „ν†µ μμƒ, μ„μΈμ μ „ν†µ μμ•…, μ„μΈμ μ „ν†µ μ „μ‹νλ¥Ό λ°©λ¬Έν•μ—¬ μ„μΈμ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”.\n",
      "\n",
      "### μ„μΈμ μ—­μ‚¬μ  Sites\n",
      "\n",
      "1.  **κ³ λ ¤μ‹λ€(κ³ λ ¤, κ³ λ ¤μ‹λ€, κ³ λ ¤μ™•κµ­)**\n",
      "\n",
      "    *   **κ³ λ ¤μ μ—­μ‚¬μ  sites** : κ³ λ ¤μ μ—­μ‚¬μ  sitesλ¥Ό λ°©λ¬Έν•μ—¬ κ³ λ ¤μ‹λ€μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”. \n",
      "\n",
      "    *   **κ³ λ ¤μ μ—­μ‚¬μ  sites** : κ³ λ ¤μ μ—­μ‚¬μ  sitesλ¥Ό λ°©λ¬Έν•μ—¬ κ³ λ ¤μ‹λ€μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”. \n",
      "\n",
      "2.  **μ¤‘μ„Έμ‹λ€(κ³ λ ¤, κ³ λ ¤μ‹λ€, κ³ λ ¤μ™•κµ­)**\n",
      "\n",
      "    *   **κ³ λ ¤μ μ—­μ‚¬μ  sites** : κ³ λ ¤μ μ—­μ‚¬μ  sitesλ¥Ό λ°©λ¬Έν•μ—¬ μ¤‘μ„Έμ‹λ€μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”. \n",
      "\n",
      "    *   **κ³ λ ¤μ μ—­μ‚¬μ  sites** : κ³ λ ¤μ μ—­μ‚¬μ  sitesλ¥Ό λ°©λ¬Έν•μ—¬ μ¤‘μ„Έμ‹λ€μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”. \n",
      "\n",
      "3.  **ν„λ€μ‹λ€(μ„μΈ, κ³ λ ¤, κ³ λ ¤μ‹λ€)**\n",
      "\n",
      "    *   **μ„μΈμ μ—­μ‚¬μ  sites** : μ„μΈμ μ—­μ‚¬μ  sitesλ¥Ό λ°©λ¬Έν•μ—¬ ν„λ€μ‹λ€μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”. \n",
      "\n",
      "    *   **μ„μΈμ μ—­μ‚¬μ  sites** : μ„μΈμ μ—­μ‚¬μ  sitesλ¥Ό λ°©λ¬Έν•μ—¬ ν„λ€μ‹λ€μ μ—­μ‚¬μ™€ λ¬Έν™”λ¥Ό κΉμ΄ μ΄ν•΄ν•΄λ³΄μ„Έμ”. \n",
      "\n",
      "### μ„μΈμ λ¬Έν™”μ  μƒμ§•\n",
      "\n",
      "1.  **κ³ λ ¤μ μ „ν†µ μμƒ** : κ³ λ ¤μ μ „ν†µ μμƒ, μλ¥Ό λ“¤μ–΄ κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μμƒ, κ³ λ ¤μ μ „ν†µ μ\n",
      "\n",
      "[4λΉ„νΈ μ–‘μν™”] μ¶”λ΅  μ‹ GPU μ‚¬μ©λ‰: 2158.84MB (μµλ€ 2284.44MB)\n",
      "\n",
      "π“ μµμΆ… λΉ„κµ κ²°κ³Ό:\n",
      "π”Ή λ¨λΈ λ΅λ“ ν›„ GPU μ μ•½λ‰ (8λΉ„νΈ): 2676.92MB (μµλ€ 2652.97MB)\n",
      "π”Ή λ¨λΈ λ΅λ“ ν›„ GPU μ μ•½λ‰ (4λΉ„νΈ): 3969.50MB (μµλ€ 3932.40MB)\n",
      "π”Ή λ¨λΈ μ¶”λ΅  μ‹ GPU μ μ•½λ‰ (8λΉ„νΈ): 2683.25MB (μµλ€ 2682.29MB)\n",
      "π”Ή λ¨λΈ μ¶”λ΅  μ‹ GPU μ μ•½λ‰ (4λΉ„νΈ): 3977.62MB (μµλ€ 3977.63MB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "def get_gpu_memory():\n",
    "    \"\"\"GPU λ©”λ¨λ¦¬ μ‚¬μ©λ‰ λ°ν™ (MB λ‹¨μ„)\"\"\"\n",
    "    torch.cuda.synchronize()\n",
    "    mem_used = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "    peak_mem_used = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
    "    return mem_used, peak_mem_used\n",
    "\n",
    "def run_inference(model, tokenizer, prompt):\n",
    "    \"\"\"λ¨λΈ μ¶”λ΅  λ° GPU λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μΈ΅μ •\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_length=1024)\n",
    "\n",
    "    mem_used, peak_mem_used = get_gpu_memory()\n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return output_text, mem_used, peak_mem_used\n",
    "\n",
    "model_id = 'Bllossom/llama-3.2-Korean-Bllossom-3B'\n",
    "tokenizer_base = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "model_base = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "mem_base, peak_mem_base = get_gpu_memory()\n",
    "print(f\"μ–‘μν™” μ „ λ¨λΈ GPU μ‚¬μ©λ‰: {mem_base:.2f}MB (μµλ€ {peak_mem_base:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "prompt = \"μ„μΈμ κ΄€κ΄‘μ½”μ¤λ¥Ό μ§κ³  μ‹¶μµλ‹λ‹¤. μ™Έκµ­μΈμ΄ μ™”μ„ λ• μ—­μ‚¬μ μΌλ΅ λ§μ€ κ²½ν—μ„ μ–»μ„ μ μλ„λ΅ μ„¤κ³„ν•΄μ£Όμ„Έμ”\"\n",
    "output_base, inf_mem_base, peak_inf_mem_base = run_inference(model_base, tokenizer_base, prompt)\n",
    "print(f\"[μ–‘μν™” μ „] λ¨λΈ μ¶λ ¥: {output_base}\", end=\"\\n\\n\")\n",
    "print(f\"[μ–‘μν™” μ „] μ¶”λ΅  μ‹ GPU μ‚¬μ©λ‰: {inf_mem_base:.2f}MB (μµλ€ {peak_inf_mem_base:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "del model_base\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "tokenizer_8bit = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "model_8bit = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "mem_8bit, peak_mem_8bit = get_gpu_memory()\n",
    "print(f\"8λΉ„νΈ μ–‘μν™” ν›„ λ¨λΈ GPU μ‚¬μ©λ‰: {mem_8bit:.2f}MB (μµλ€ {peak_mem_8bit:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "output_8bit, inf_mem_8bit, peak_inf_mem_8bit = run_inference(model_8bit, tokenizer_8bit, prompt)\n",
    "print(f\"[8λΉ„νΈ μ–‘μν™”] λ¨λΈ μ¶λ ¥: {output_8bit}\", end=\"\\n\\n\")\n",
    "print(f\"[8λΉ„νΈ μ–‘μν™”] μ¶”λ΅  μ‹ GPU μ‚¬μ©λ‰: {inf_mem_8bit:.2f}MB (μµλ€ {peak_inf_mem_8bit:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "del model_8bit\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "quantization_config_4bit = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "tokenizer_4bit = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "model_4bit = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config_4bit,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "\n",
    "mem_4bit, peak_mem_4bit = get_gpu_memory()\n",
    "print(f\"4λΉ„νΈ μ–‘μν™” ν›„ λ¨λΈ GPU μ‚¬μ©λ‰: {mem_4bit:.2f}MB (μµλ€ {peak_mem_4bit:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "output_4bit, inf_mem_4bit, peak_inf_mem_4bit = run_inference(model_4bit, tokenizer_4bit, prompt)\n",
    "print(f\"[4λΉ„νΈ μ–‘μν™”] λ¨λΈ μ¶λ ¥: {output_4bit}\", end=\"\\n\\n\")\n",
    "print(f\"[4λΉ„νΈ μ–‘μν™”] μ¶”λ΅  μ‹ GPU μ‚¬μ©λ‰: {inf_mem_4bit:.2f}MB (μµλ€ {peak_inf_mem_4bit:.2f}MB)\", end=\"\\n\\n\")\n",
    "\n",
    "del model_4bit\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "print(\"π“ μµμΆ… λΉ„κµ κ²°κ³Ό:\")\n",
    "print(f\"π”Ή λ¨λΈ λ΅λ“ ν›„ GPU μ μ•½λ‰ (8λΉ„νΈ): {mem_base - mem_8bit:.2f}MB (μµλ€ {peak_mem_base - peak_mem_8bit:.2f}MB)\")\n",
    "print(f\"π”Ή λ¨λΈ λ΅λ“ ν›„ GPU μ μ•½λ‰ (4λΉ„νΈ): {mem_base - mem_4bit:.2f}MB (μµλ€ {peak_mem_base - peak_mem_4bit:.2f}MB)\")\n",
    "print(f\"π”Ή λ¨λΈ μ¶”λ΅  μ‹ GPU μ μ•½λ‰ (8λΉ„νΈ): {inf_mem_base - inf_mem_8bit:.2f}MB (μµλ€ {peak_inf_mem_base - peak_inf_mem_8bit:.2f}MB)\")\n",
    "print(f\"π”Ή λ¨λΈ μ¶”λ΅  μ‹ GPU μ μ•½λ‰ (4λΉ„νΈ): {inf_mem_base - inf_mem_4bit:.2f}MB (μµλ€ {peak_inf_mem_base - peak_inf_mem_4bit:.2f}MB)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## κ²°λ΅ \n",
    "- 4λΉ„νΈ μ–‘μν™”κ°€ κ°€μ¥ ν° GPU λ©”λ¨λ¦¬ μ μ•½ ν¨κ³Όλ¥Ό λ³΄μ„\n",
    "- 8λΉ„νΈ μ–‘μν™”λ„ ν¨κ³Όμ μ΄μ§€λ§, 4λΉ„νΈλ³΄λ‹¤λ” λ©”λ¨λ¦¬λ¥Ό λ” λ§μ΄ μ‚¬μ©\n",
    "- μ–‘μν™”λ¥Ό ν•  μλ΅ λ‹µλ³€μ ν€„λ¦¬ν‹°κ°€ λ–¨μ–΄μ§€λ‹¤κ°€, 4λΉ„νΈμ—μ„λ¶€ν„°λ” λ€λ‹µμ΄ λ§κ°€μ§„ κ²ƒμ„ ν™•μΈ\n",
    "- μ΄ν›„ μ±—λ΄‡μ— μ—®μ–΄μ„ μ§„ν–‰ν•  μμ •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>μ–‘μν™” λ°©μ‹</th>\n",
       "      <th>λ¨λΈ λ΅λ“ GPU μ‚¬μ©λ‰ (MB)</th>\n",
       "      <th>λ¨λΈ λ΅λ“ μµλ€ GPU μ‚¬μ©λ‰ (MB)</th>\n",
       "      <th>μ¶”λ΅  GPU μ‚¬μ©λ‰ (MB)</th>\n",
       "      <th>μ¶”λ΅  μµλ€ GPU μ‚¬μ©λ‰ (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>λΉ„μ–‘μν™”</td>\n",
       "      <td>6128.334473</td>\n",
       "      <td>6128.334473</td>\n",
       "      <td>6136.468262</td>\n",
       "      <td>6262.069336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8λΉ„νΈ μ–‘μν™”</td>\n",
       "      <td>3451.412598</td>\n",
       "      <td>3475.369141</td>\n",
       "      <td>3453.213379</td>\n",
       "      <td>3579.779297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4λΉ„νΈ μ–‘μν™”</td>\n",
       "      <td>2158.835449</td>\n",
       "      <td>2195.937500</td>\n",
       "      <td>2158.844238</td>\n",
       "      <td>2284.437500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    μ–‘μν™” λ°©μ‹  λ¨λΈ λ΅λ“ GPU μ‚¬μ©λ‰ (MB)  λ¨λΈ λ΅λ“ μµλ€ GPU μ‚¬μ©λ‰ (MB)  μ¶”λ΅  GPU μ‚¬μ©λ‰ (MB)  \\\n",
       "0     λΉ„μ–‘μν™”         6128.334473            6128.334473      6136.468262   \n",
       "1  8λΉ„νΈ μ–‘μν™”         3451.412598            3475.369141      3453.213379   \n",
       "2  4λΉ„νΈ μ–‘μν™”         2158.835449            2195.937500      2158.844238   \n",
       "\n",
       "   μ¶”λ΅  μµλ€ GPU μ‚¬μ©λ‰ (MB)  \n",
       "0         6262.069336  \n",
       "1         3579.779297  \n",
       "2         2284.437500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# λ°μ΄ν„° μ •λ¦¬\n",
    "data = {\n",
    "    \"μ–‘μν™” λ°©μ‹\": [\"λΉ„μ–‘μν™”\", \"8λΉ„νΈ μ–‘μν™”\", \"4λΉ„νΈ μ–‘μν™”\"],\n",
    "    \"λ¨λΈ λ΅λ“ GPU μ‚¬μ©λ‰ (MB)\": [mem_base, mem_8bit, mem_4bit],\n",
    "    \"λ¨λΈ λ΅λ“ μµλ€ GPU μ‚¬μ©λ‰ (MB)\": [peak_mem_base, peak_mem_8bit, peak_mem_4bit],\n",
    "    \"μ¶”λ΅  GPU μ‚¬μ©λ‰ (MB)\": [inf_mem_base, inf_mem_8bit, inf_mem_4bit],\n",
    "    \"μ¶”λ΅  μµλ€ GPU μ‚¬μ©λ‰ (MB)\": [peak_inf_mem_base, peak_inf_mem_8bit, peak_inf_mem_4bit],\n",
    "}\n",
    "\n",
    "# λ°μ΄ν„°ν”„λ μ„ μƒμ„±\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "μ±—λ΄‡μ—μ„ μ•„λμ™€ κ°™μ€ ν•νƒλ΅ 4λΉ„νΈ μ–‘μν™”λ¥Ό ν•μ—¬ λ¨λΈμ„ κµ¬ν„ν–μµλ‹λ‹¤.\n",
    "\n",
    "```python\n",
    "model_id = 'Bllossom/llama-3.2-Korean-Bllossom-3B'\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "custom_pipeline = KoreanLlamaPipeline(model, tokenizer)\n",
    "llm = KoreanLlamaLangChainLLM(pipeline=custom_pipeline)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
