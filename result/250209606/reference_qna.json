{
    "11": {
        "Title": "Monitoring ai-modified content at scale: A case study on the impact of chatgpt on ai conference peer reviews",
        "Authors": "Weixin Liang, Zachary Izzo, Yaohui Zhang, Haley Lepp, Hancheng Cao, Xuandong Zhao, Lingjiao Chen, Hao-tian Ye, Sheng Liu, Zhi Huang, et al.",
        "Counter": 9,
        "Context": [
            "Empirical studies from April 2024 observed that the frequency of certain words used in academic papers published in 2023 had changed and confirmed a strong correlation between these changes and the use of LLMs (Liang et al., 2024b; Geng and Trotta, 2024).",
            "which corresponds to the time when researchers identified these words in AI conference peer reviews (Liang et al., 2024a) and academic papers (Liang et al., 2024b).",
            "Figure 2a shows the frequency of the 4 words highlighted by Liang et al. (2024b) and Figure 2b presents the frequency of the 6 words emphasized by Liang et al. (2024a).",
            "Survey results also show that many researchers are utilizing LLMs in their work (Liao et al., 2024).",
            "which corresponds to the time when researchers identified these words in AI conference peer reviews (Liang et al., 2024a) and academic papers (Liang et al., 2024b).",
            "Figure 2a shows the frequency of the 4 words highlighted by Liang et al. (2024b) and Figure 2b presents the frequency of the 6 words emphasized by Liang et al. (2024a).",
            "Empirical studies from April 2024 observed that the frequency of certain words used in academic papers published in 2023 had changed and confirmed a strong correlation between these changes and the use of LLMs (Liang et al., 2024b; Geng and Trotta, 2024)."
        ],
        "abstract": "We present an approach for estimating the fraction of text in a large corpus\nwhich is likely to be substantially modified or produced by a large language\nmodel (LLM). Our maximum likelihood model leverages expert-written and\nAI-generated reference texts to accurately and efficiently examine real-world\nLLM-use at the corpus level. We apply this approach to a case study of\nscientific peer review in AI conferences that took place after the release of\nChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023. Our results suggest\nthat between 6.5% and 16.9% of text submitted as peer reviews to these\nconferences could have been substantially modified by LLMs, i.e. beyond\nspell-checking or minor writing updates. The circumstances in which generated\ntext occurs offer insight into user behavior: the estimated fraction of\nLLM-generated text is higher in reviews which report lower confidence, were\nsubmitted close to the deadline, and from reviewers who are less likely to\nrespond to author rebuttals. We also observe corpus-level trends in generated\ntext which may be too subtle to detect at the individual level, and discuss the\nimplications of such trends on peer review. We call for future\ninterdisciplinary work to examine how LLM use is changing our information and\nknowledge practices.",
        "pdf_url": "http://arxiv.org/pdf/2403.07183v2",
        "Questions": "1. Empirical studies from April 2024 observed that the frequency of certain words used in academic papers published in 2023 had changed and confirmed a strong correlation between these changes and the use of LLMs (Liang et al., 2024b; Geng and Trotta, 2024).\n2. Survey results also show that many researchers are utilizing LLMs in their work (Liao et al., 2024).\n3. Figure 2a shows the frequency of the 4 words highlighted by Liang et al. (2024b) and Figure 2b presents the frequency of the 6 words emphasized by Liang et al. (2024a).",
        "Summary": "이 연구는 ChatGPT와 같은 대형 언어 모델(LLM)이 AI 학회 피어 리뷰에 미치는 영향을 분석하는 방법론을 제시합니다. 2024년 4월의 실증 연구에 따르면, 2023년에 발표된 학술 논문에서 특정 단어의 사용 빈도가 변화했으며, 이는 LLM 사용과 강한 상관관계를 나타냅니다. 설문 조사 결과에 따르면 많은 연구자들이 LLM을 활용하고 있으며, ICLR 2024, NeurIPS 2023, EMNLP 2023 등에서 제출된 리뷰의 6.5%에서 16.9%가 LLM에 의해 상당히 수정되었음을 발견했습니다. 특히, LLM 사용은 피어 리뷰의 자신감이 낮거나 마감일에 가까운 리뷰에서 더 빈번하게 나타났으며, 학술 인용이 없는 리뷰에서 LLM 사용 비율이 더 높았습니다. 이러한 경향은 LLM이 정보 생태계에서 점차적으로 변화를 초래하고 있음을 시사합니다."
    },
    "16": {
        "Title": "Human-ai co-evolution",
        "Authors": "Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-László Barabási, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, János Kertész, et al.",
        "Counter": 7,
        "Context": [
            "The coevolution of AI and humans has also been recognized by researchers (Pedreschi et al., 2024).",
            "Humans and LLMs are coevolving and we can already conclude that, for this reason, the impact.",
            "The coevolution of AI and humans has also been recognized by researchers (Pedreschi et al., 2024).",
            "Humans and LLMs are coevolving and we can already conclude that, for this reason, the impact...",
            "The coevolution of AI and humans has also been recognized by researchers (Pedreschi et al., 2024).",
            "The frequency of some other words (e.g., 'intricate' and 'delve') associated with LLMs begins to decrease after March and April 2024, which corresponds to the time when researchers identified these words in AI conference peer reviews (Liang et al., 2024a) and academic papers (Liang et al., 2024b).",
            "Humans and LLMs are coevolving and we can already conclude that, for this reason, the impact..."
        ],
        "abstract": "Substantial empirical research has shown that the level of individualism vs.\ncollectivism is one of the most critical and important determinants of societal\ntraits, such as economic growth, economic institutions and health conditions.\nBut the exact nature of this impact has thus far not been well understood in an\nanalytical setting. In this work, we develop one of the first theoretical\nmodels that analytically studies the impact of individualism-collectivism on\nthe society. We model the growth of an individual's welfare (wealth, resources\nand health) as depending not only on himself, but also on the level of\ncollectivism, i.e. the level of dependence on the rest of the individuals in\nthe society, which leads to a co-evolutionary setting. Based on our model, we\nare able to predict the impact of individualism-collectivism on various\nsocietal metrics, such as average welfare, average life-time, total population,\ncumulative welfare and average inequality. We analytically show that\nindividualism has a positive impact on average welfare and cumulative welfare,\nbut comes with the drawbacks of lower average life-time, lower total population\nand higher average inequality.",
        "pdf_url": "http://arxiv.org/pdf/1411.5107v1",
        "Questions": "1. The coevolution of AI and humans has also been recognized by researchers (Pedreschi et al., 2024).\n2. The frequency of some other words (e.g., 'intricate' and 'delve') associated with LLMs begins to decrease after March and April 2024, which corresponds to the time when researchers identified these words in AI conference peer reviews (Liang et al., 2024a) and academic papers (Liang et al., 2024b).",
        "Summary": "인용 논문 \"Human-ai co-evolution\"에서 연구자들은 AI와 인간의 공동 진화 과정을 인식하고 있으며, 이는 사회적 발전에 미치는 영향이 크다고 주장하고 있습니다. 특히, 개인주의와 집단주의 간의 상호작용이 사회적 특성, 경제 성장 및 건강 조건에 중요한 영향을 미친다는 점이 강조됩니다. 2024년 3월과 4월 이후 '복잡한(intricate)' 및 '파고들다(delve)'와 같은 LLM 관련 단어의 사용 빈도가 감소하는 경향이 관찰되었으며, 이는 AI 관련 학술회의와 논문에서 이러한 단어들이 식별된 시기와 일치합니다. 이러한 연구는 개인의 복지 수준이 집단주의적 사회에서는 낮을 수 있지만 평균 생존 기간은 길어질 수 있음을 보여줍니다. 따라서, 개인주의적 사회는 평균 복지 수준이 높지만 불평등이 심화되는 경향이 있으며, 이는 사회적 지원의 차이에서 기인합니다."
    },
    "12": {
        "Title": "Mapping the increasing use of llms in scientific papers",
        "Authors": "Weixin Liang, Yaohui Zhang, Zhengxuan Wu, Haley Lepp, Wenlong Ji, Xuandong Zhao, Hancheng Cao, Sheng Liu, Siyu He, Zhi Huang, et al.",
        "Counter": 4,
        "Context": [
            "The frequency of some other words (e.g., 'intricate' and 'delve') associated with LLMs begins to decrease after March and April 2024, which corresponds to the time when researchers identified these words in AI conference peer reviews (Liang et al., 2024a) and academic papers (Liang et al., 2024b).",
            "Figure 1 illustrates the evolution in the frequency usage of some of the words that were singled out as favored by ChatGPT around April 2024.",
            "Figure 2a shows the frequency of the 4 words highlighted by Liang et al. (2024b) and Figure 2b presents the frequency of the 6 words emphasized by Liang et al. (2024a).",
            "A study published in December 2024 also observed a decline in the use of certain words, such as 'delve', in some selected arXiv papers (Leiter et al., 2024)."
        ],
        "abstract": "Scientific publishing lays the foundation of science by disseminating\nresearch findings, fostering collaboration, encouraging reproducibility, and\nensuring that scientific knowledge is accessible, verifiable, and built upon\nover time. Recently, there has been immense speculation about how many people\nare using large language models (LLMs) like ChatGPT in their academic writing,\nand to what extent this tool might have an effect on global scientific\npractices. However, we lack a precise measure of the proportion of academic\nwriting substantially modified or produced by LLMs. To address this gap, we\nconduct the first systematic, large-scale analysis across 950,965 papers\npublished between January 2020 and February 2024 on the arXiv, bioRxiv, and\nNature portfolio journals, using a population-level statistical framework to\nmeasure the prevalence of LLM-modified content over time. Our statistical\nestimation operates on the corpus level and is more robust than inference on\nindividual instances. Our findings reveal a steady increase in LLM usage, with\nthe largest and fastest growth observed in Computer Science papers (up to\n17.5%). In comparison, Mathematics papers and the Nature portfolio showed the\nleast LLM modification (up to 6.3%). Moreover, at an aggregate level, our\nanalysis reveals that higher levels of LLM-modification are associated with\npapers whose first authors post preprints more frequently, papers in more\ncrowded research areas, and papers of shorter lengths. Our findings suggests\nthat LLMs are being broadly used in scientific writings.",
        "pdf_url": "http://arxiv.org/pdf/2404.01268v1",
        "Questions": "1. The frequency of some other words (e.g., 'intricate' and 'delve') associated with LLMs begins to decrease after March and April 2024, which corresponds to the time when researchers identified these words in AI conference peer reviews (Liang et al., 2024a) and academic papers (Liang et al., 2024b).\n2. Figure 1 illustrates the evolution in the frequency usage of some of the words that were singled out as favored by ChatGPT around April 2024.\n3. A study published in December 2024 also observed a decline in the use of certain words, such as 'delve', in some selected arXiv papers (Leiter et al., 2024).",
        "Summary": "이 연구는 2020년 1월부터 2024년 2월까지의 950,965개의 논문을 분석하여 대형 언어 모델(LLMs)의 사용 증가를 정량화한 결과를 보고합니다. 특히, 2022년 11월 ChatGPT 출시 이후, 연구자들은 'intricate'와 'delve'와 같은 특정 단어의 사용 빈도가 2024년 3월과 4월에 감소하는 경향을 보였으며, 이는 AI 회의 피어 리뷰와 학술 논문에서 이러한 단어들이 식별된 시점과 일치합니다. 또한, 컴퓨터 과학 분야에서 LLM 수정 비율이 가장 높았으며, 특히 저자가 프리프린트를 자주 게시하는 경향이 LLM 사용 증가와 관련이 있음을 발견했습니다. 이와 같은 경향은 연구의 경쟁적이고 빠른 환경에서 시간이 부족한 저자들이 LLM을 활용하는 이유를 시사합니다. 마지막으로, 연구는 LLM 사용이 특정 연구 분야에서의 유사성과 논문의 길이와도 관련이 있음을 보여주며, 이는 LLM이 학술 출판의 구조적 문제를 드러내는 데 기여할 수 있음을 강조합니다."
    },
    "3": {
        "Title": "The impact of large language models in academia: from writing to speaking",
        "Authors": "Mingmeng Geng, Caixi Chen, Yanru Wu, Dongping Chen, Yao Wan, and Pan Zhou",
        "Counter": 3,
        "Context": [
            "Researchers are constantly proposing new detection techniques, but the language and expressions of LLM users are also likely evolving due to their use of LLMs (Geng et al., 2024).",
            "Researchers are constantly proposing new detection techniques, but the language and expressions of LLM users are also likely evolving due to their use of LLMs (Geng et al., 2024).",
            "Changes in the words used in academic writing, as discussed above, serve as an excellent example of AI and human coevolution. Researchers are constantly proposing new detection techniques, but the language and expressions of LLM users are also likely evolving due to their use of LLMs (Geng et al., 2024)."
        ],
        "abstract": "Large language models (LLMs) are increasingly impacting human society,\nparticularly in textual information. Based on more than 30,000 papers and 1,000\npresentations from machine learning conferences, we examined and compared the\nwords used in writing and speaking, representing the first large-scale study of\nhow LLMs influence the two main modes of verbal communication and expression\nwithin the same group of people. Our empirical results show that LLM-style\nwords such as \"significant\" have been used more frequently in abstracts and\noral presentations. The impact on speaking is beginning to emerge and is likely\nto grow in the future, calling attention to the implicit influence and ripple\neffect of LLMs on human society.",
        "pdf_url": "http://arxiv.org/pdf/2409.13686v2",
        "Questions": "1. Researchers are constantly proposing new detection techniques, but the language and expressions of LLM users are also likely evolving due to their use of LLMs (Geng et al., 2024).\n2. Changes in the words used in academic writing, as discussed above, serve as an excellent example of AI and human coevolution.",
        "Summary": "대규모 언어 모델(LLM)의 사용이 학계에서의 글쓰기와 말하기에 미치는 영향을 분석한 연구에 따르면, LLM 사용자들이 사용하는 언어와 표현이 변화하고 있으며, 이는 AI와 인간의 공진화의 좋은 예로 여겨진다. 연구 결과, LLM 스타일의 단어들이 학술 발표와 초록에서 더 자주 사용되고 있으며, 이는 LLM의 영향력이 점차 확대되고 있음을 나타낸다. 또한, LLM의 영향은 단순히 텍스트 생성에 그치지 않고, 사람들이 LLM을 통해 접한 내용을 바탕으로 언어 표현이 변화하는 방식에서도 나타난다. 이 연구는 LLM이 학술적 글쓰기와 발표에서 어떤 방식으로 언어 사용에 영향을 미치는지를 조사하며, 그 결과는 LLM이 학계에서 점점 더 중요한 역할을 하고 있음을 시사한다. 따라서, LLM의 사용이 학술 커뮤니케이션의 방식에 미치는 영향에 대한 인식이 필요하다고 강조하고 있다."
    },
    "7": {
        "Title": "Benchmarking linguistic diversity of large language models",
        "Authors": "Yanzhu Guo, Guokan Shang, and Chloé Clavel",
        "Counter": 3,
        "Context": [
            "More researchers have now noticed issues with word usage and diversity in LLM-generated content (Kobak et al., 2024; Reviriego et al., 2024; Guo et al., 2024).",
            "More researchers have now noticed issues with word usage and diversity in LLM-generated content (Kobak et al., 2024; Reviriego et al., 2024; Guo et al., 2024).",
            "More researchers have now noticed issues with word usage and diversity in LLM-generated content (Kobak et al., 2024; Reviriego et al., 2024; Guo et al., 2024)."
        ],
        "abstract": "The development and evaluation of Large Language Models (LLMs) has primarily\nfocused on their task-solving capabilities, with recent models even surpassing\nhuman performance in some areas. However, this focus often neglects whether\nmachine-generated language matches the human level of diversity, in terms of\nvocabulary choice, syntactic construction, and expression of meaning, raising\nquestions about whether the fundamentals of language generation have been fully\naddressed. This paper emphasizes the importance of examining the preservation\nof human linguistic richness by language models, given the concerning surge in\nonline content produced or aided by LLMs. We propose a comprehensive framework\nfor evaluating LLMs from various linguistic diversity perspectives including\nlexical, syntactic, and semantic dimensions. Using this framework, we benchmark\nseveral state-of-the-art LLMs across all diversity dimensions, and conduct an\nin-depth case study for syntactic diversity. Finally, we analyze how different\ndevelopment and deployment choices impact the linguistic diversity of LLM\noutputs.",
        "pdf_url": "http://arxiv.org/pdf/2412.10271v1",
        "Questions": "1. More researchers have now noticed issues with word usage and diversity in LLM-generated content (Kobak et al., 2024; Reviriego et al., 2024; Guo et al., 2024).",
        "Summary": "최근 연구자들은 대규모 언어 모델(LLM)이 생성하는 콘텐츠의 단어 사용 및 다양성 문제에 대해 주목하고 있으며, 이들 모델이 인간의 언어 표현의 뉘앙스와 변화를 반영하는 데 어려움을 겪고 있다는 점을 강조하고 있습니다. 이러한 문제를 해결하기 위해, 연구자들은 LLM의 언어 다양성을 평가하기 위한 종합적인 프레임워크를 제안하고 있으며, 이 프레임워크는 어휘적, 구문적, 의미적 차원에서 LLM의 성능을 벤치마킹합니다. 연구 결과, LLM은 창의성이 요구되는 작업에서 인간에 비해 언어 다양성이 현저히 낮은 경향이 있으며, 이는 모델의 훈련 데이터와 개발 선택에 따라 더욱 악화될 수 있습니다. 특히, LLM의 훈련 과정에서 합성 데이터로 학습할 경우 언어 다양성이 감소하는 경향이 있으며, 이는 모델의 출력이 동질화되는 문제를 초래할 수 있습니다. 따라서, 향후 LLM 개발에서는 성능 최적화와 함께 언어 다양성의 유지가 중요하다는 점이 강조됩니다."
    }
}